{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeynepaydin34/Baker/blob/main/Classification-Cleaning_Augmentation_Training_FineTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_AqeuHYd8c5",
        "outputId": "bf89c178-9e7f-4494-b90f-de1a28b41356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Temizlik tamamlandı. Satır sayısı: 1048\n"
          ]
        }
      ],
      "source": [
        "# 1. Adım: Drive'ı bağla ve veri yükle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import unicodedata\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "TEXT_COLUMN = 'temizlenmis_metin'\n",
        "ANA_KATEGORILER = ['ÜCRET İADESİ','BAGAJ','MÜŞTERİ HİZMETLERİ','UYGULAMA/TEKNİK','RÖTAR']\n",
        "\n",
        "# Dosya yolu\n",
        "DOSYA_ADI = '/content/drive/MyDrive/BİTİRME/Labeled_Data.xlsx'\n",
        "\n",
        "# Veri yükle\n",
        "df = pd.read_excel(DOSYA_ADI)\n",
        "df.columns = [col.strip().replace(' ', '').replace('İ', 'I') for col in df.columns]\n",
        "\n",
        "# Metin birleştirme\n",
        "df['metin'] = df[['Baslik', 'Icerik', 'Kategori1', 'Kategori2']].fillna('').agg(' '.join, axis=1)\n",
        "\n",
        "# Temizlik için stopwords\n",
        "stop_words_tr = set(nltk.corpus.stopwords.words('turkish'))\n",
        "ek_stop_words = {'rica', 'bilgi', 'olay', 'durum', 'yapmak', 'etmek', 'olmak',\n",
        "                 'süre', 'değil', 'gerekli', 'taraf', 'istemek', 'istiyorum', 'yapılmasını',\n",
        "                 'gerek', 'nedeniyle', 'a', 'o', 'bu', 'ki', 'için', 'ile', 've', 'ya', 'bir',\n",
        "                 'ben', 'sen', 'biz', 'siz'}\n",
        "stop_words_tr.update(ek_stop_words)\n",
        "\n",
        "# Temizlik fonksiyonları\n",
        "def nlp_clean(text):\n",
        "    if pd.isna(text) or text is None: return \"\"\n",
        "    text = str(text).lower()\n",
        "    text = unicodedata.normalize('NFKC', text)\n",
        "    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
        "    text = re.sub(r'[\\d€$₺£]', ' ', text)\n",
        "    text = re.sub(r'\\s*\\S+@\\S+|\\s*https?://\\S+|\\s*www\\.\\S+', ' ', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    kelimeler = text.split()\n",
        "    kelimeler = [k for k in kelimeler if k not in stop_words_tr]\n",
        "    return \" \".join(kelimeler).strip()\n",
        "\n",
        "def fix_unicode(text):\n",
        "    replacements = {'i̇': 'i', 'I': 'ı', 'İ': 'i', 'Ö': 'ö', 'Ü': 'ü', 'Ç': 'ç', 'Ş': 'ş', 'Ğ': 'ğ'}\n",
        "    for wrong, correct in replacements.items():\n",
        "        text = text.replace(wrong, correct)\n",
        "    return text.strip()\n",
        "\n",
        "# Temizleme uygula\n",
        "df[TEXT_COLUMN] = df['metin'].apply(nlp_clean).apply(fix_unicode)\n",
        "\n",
        "# Minimum filtreleme\n",
        "df = df[df[TEXT_COLUMN].str.split().str.len() > 3]\n",
        "df = df.dropna(subset=['Kategori1'])\n",
        "\n",
        "# Multi-label encoding\n",
        "for kategori in ANA_KATEGORILER:\n",
        "    df[kategori] = ((df['Kategori1'] == kategori) | (df['Kategori2'] == kategori)).astype(int)\n",
        "\n",
        "print(f\"✅ Temizlik tamamlandı. Satır sayısı: {len(df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPm9ytzylP6l",
        "outputId": "352ce18c-ae61-4f7f-a7d3-50f608d026f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Veri Seti Boyutları: Train: 838, Val: 105, Test: 105\n",
            "\n",
            "✅ Veri ayırma (Train/Val/Test) tamamlandı. Sınıf Ağırlığı Hesaplamasına geçebilirsiniz.\n"
          ]
        }
      ],
      "source": [
        "# 3. ADIM: Veriyi Ayırma (Train, Validation, Test: 80-10-10)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Metinleri ve etiketleri ayır\n",
        "X = df[TEXT_COLUMN]  # df_clean yerine df kullan\n",
        "y = df[ANA_KATEGORILER]\n",
        "\n",
        "# 80% Train/Val, 10% Test\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    X, y, test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "# Kalan %90'ı 8/1 oranında Train ve Val olarak ayır (yani 80% Train, 10% Val)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=(0.1/0.9), random_state=42\n",
        ")\n",
        "\n",
        "# DataFrame oluştur\n",
        "train_df = pd.DataFrame({TEXT_COLUMN: X_train, **y_train}).reset_index(drop=True)\n",
        "val_df = pd.DataFrame({TEXT_COLUMN: X_val, **y_val}).reset_index(drop=True)\n",
        "test_df = pd.DataFrame({TEXT_COLUMN: X_test, **y_test}).reset_index(drop=True)\n",
        "\n",
        "print(f\"Veri Seti Boyutları: Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n",
        "print(\"\\n✅ Veri ayırma (Train/Val/Test) tamamlandı. Sınıf Ağırlığı Hesaplamasına geçebilirsiniz.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Multi-label Dengeli Oversampling (Iteratif)\n",
        "# =========================================================\n",
        "import pandas as pd\n",
        "import random\n",
        "from deep_translator import GoogleTranslator\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# GPU kontrolü\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"✅ Çalışma cihazı: {device}\")\n",
        "\n",
        "# Back-Translation Fonksiyonu (CPU'da çalışır)\n",
        "def back_translate(text, src='tr', mid='en'):\n",
        "    try:\n",
        "        trans = GoogleTranslator(source=src, target=mid).translate(text)\n",
        "        back = GoogleTranslator(source=mid, target=src).translate(trans)\n",
        "        if back is None or back.lower().strip() == text.lower().strip():\n",
        "            return text\n",
        "        return back\n",
        "    except Exception:\n",
        "        return text\n",
        "\n",
        "# Hedef sınıf sayısını belirle (en büyük sınıf)\n",
        "MAX_CLASS_COUNT = train_df[ANA_KATEGORILER].sum().max()\n",
        "print(\"=\"*60)\n",
        "print(\"Başlatılıyor: Dengeli Oversampling + Back-Translation (Multi-label)\")\n",
        "print(f\"Orijinal TRAIN SETİ boyutu: {len(train_df)}\")\n",
        "print(f\"En büyük sınıf sayısı (hedef): {MAX_CLASS_COUNT}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Iteratif oversampling\n",
        "augmented_frames = []\n",
        "\n",
        "# Kopya ekleme fonksiyonu\n",
        "def add_sample(row):\n",
        "    new_row = row.copy()\n",
        "    new_row[TEXT_COLUMN] = back_translate(row[TEXT_COLUMN])\n",
        "    return new_row\n",
        "\n",
        "# Tüm sınıfların hedefe ulaşana kadar iteratif ekleme\n",
        "while True:\n",
        "    label_counts = train_df[ANA_KATEGORILER].sum()\n",
        "    min_class = label_counts.idxmin()\n",
        "    min_count = label_counts.min()\n",
        "\n",
        "    if min_count >= MAX_CLASS_COUNT:\n",
        "        break  # Tüm sınıflar hedefe ulaştı\n",
        "\n",
        "    # Min sınıftan bir örnek seç\n",
        "    candidates = train_df[train_df[min_class] == 1]\n",
        "    row = candidates.sample(n=1, replace=True).iloc[0]\n",
        "    new_row = add_sample(row)\n",
        "    train_df = pd.concat([train_df, pd.DataFrame([new_row])], ignore_index=True)\n",
        "\n",
        "print(\"\\n✅ Oversampling tamamlandı.\")\n",
        "print(f\"Yeni TRAIN SETİ boyutu: {len(train_df)}\")\n",
        "print(\"Yeni sınıf dağılımları:\")\n",
        "print(train_df[ANA_KATEGORILER].sum().sort_values(ascending=False).to_string())\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Kaydetme\n",
        "save_dir = '/content/drive/MyDrive/BİTİRME'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "save_path = os.path.join(save_dir, 'train_augmented_multi_label_balanced.xlsx')\n",
        "train_df.to_excel(save_path, index=False)\n",
        "print(f\"\\n✅ Artırılmış ve dengeli TRAIN SETİ başarıyla kaydedildi: {save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2UFxzBZBO0o",
        "outputId": "db23e2d6-9567-44a1-f824-132ac2387046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Çalışma cihazı: cuda\n",
            "============================================================\n",
            "Başlatılıyor: Dengeli Oversampling + Back-Translation (Multi-label)\n",
            "Orijinal TRAIN SETİ boyutu: 1889\n",
            "En büyük sınıf sayısı (hedef): 966\n",
            "============================================================\n",
            "\n",
            "✅ Oversampling tamamlandı.\n",
            "Yeni TRAIN SETİ boyutu: 3142\n",
            "Yeni sınıf dağılımları:\n",
            "ÜCRET İADESİ          1487\n",
            "MÜŞTERİ HİZMETLERİ    1022\n",
            "BAGAJ                  967\n",
            "UYGULAMA/TEKNİK        966\n",
            "RÖTAR                  966\n",
            "============================================================\n",
            "\n",
            "✅ Artırılmış ve dengeli TRAIN SETİ başarıyla kaydedildi: /content/drive/MyDrive/BİTİRME/train_augmented_multi_label_balanced.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 5. ADIM: Sınıflandırma Model Hazırlığı (Dengelenmiş Veri Seti İçin Optimizasyon)\n",
        "\n",
        "import torch.nn as nn\n",
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import torch\n",
        "import pandas as pd\n",
        "# NOT: MODEL_NAME, ANA_KATEGORILER, TRAIN_BATCH, EVAL_BATCH, MAX_LEN, TEXT_COLUMN\n",
        "# ve train_df, val_df değişkenlerinin tanımlı olduğunu varsayıyoruz.\n",
        "\n",
        "# Cihazı Belirle\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 5.1. Ağırlık Hesaplama (SADECE KONTROL AMAÇLI TUTULDU - KULLANILMAYACAK)\n",
        "label_counts = train_df[ANA_KATEGORILER].sum()\n",
        "print(\"\\n✅ Artırma Sonrası Yeni Sınıf Sayımları (Dengeli Olmalı):\")\n",
        "print(label_counts.sort_values(ascending=False).to_string())\n",
        "# Not: Aşağıdaki class_weights_tensor artık CustomTrainer'da kullanılmayacaktır.\n",
        "# class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "\n",
        "# 5.2. Custom Trainer (Ağırlığı DEVRE DIŞI BIRAKMAK için)\n",
        "# Veri dengelemesi yapıldığı için, ağırlıklı Loss kaldırıldı.\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # 🚨 DÜZELTME: Ağırlıksız Loss Hesaplama\n",
        "        # Artık train_df dengeli olduğu için pos_weight parametresi kaldırıldı.\n",
        "        loss_fct = nn.BCEWithLogitsLoss()\n",
        "        loss = loss_fct(logits, labels)\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# 5.3. Dataset Hazırlığı (Aynı kalıyor)\n",
        "class ComplaintDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=MAX_LEN):\n",
        "        self.texts = texts.tolist()\n",
        "        self.labels = labels.values\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        encoding = self.tokenizer(\n",
        "            text, truncation=True, padding='max_length', max_length=self.max_len, return_tensors='pt'\n",
        "        )\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "# Tokenizer ve Dataset Hazırlığı\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
        "train_dataset = ComplaintDataset(train_df[TEXT_COLUMN], train_df[ANA_KATEGORILER], tokenizer, max_len=MAX_LEN)\n",
        "val_dataset = ComplaintDataset(val_df[TEXT_COLUMN], val_df[ANA_KATEGORILER], tokenizer, max_len=MAX_LEN)\n",
        "\n",
        "# Temel BERT modelini yükle\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME, num_labels=len(ANA_KATEGORILER)\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "# Metrik Hesaplama Fonksiyonu\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    # Tahmin olasılıkları hesaplanır\n",
        "    preds = torch.sigmoid(torch.tensor(pred.predictions)).numpy()\n",
        "    # Varsayılan eşik 0.5 kullanılır\n",
        "    preds = (preds > 0.5).astype(int)\n",
        "    # Metrikler hesaplanır\n",
        "    f1 = f1_score(labels, preds, average='micro')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"f1\": f1, \"accuracy\": acc}\n",
        "\n",
        "# Eğitim Parametreleri ve Custom Trainer'ı Oluştur\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results', num_train_epochs=12, per_device_train_batch_size=TRAIN_BATCH,\n",
        "    per_device_eval_batch_size=EVAL_BATCH,\n",
        "    # Hata çözüldüğü için burayı tekrar True yapabiliriz, ancak şimdilik False kalsın\n",
        "    gradient_checkpointing=False,\n",
        "    logging_steps=50,\n",
        "    learning_rate=1e-5, weight_decay=0.01, load_best_model_at_end=False,\n",
        "    logging_dir='./logs', report_to='none', fp16=True if device.type == 'cuda' else False\n",
        ")\n",
        "\n",
        "# Custom Trainer'ı kullan\n",
        "trainer = CustomTrainer(\n",
        "    model=model, args=training_args, train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset, compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "print(\"\\n✅ Custom Trainer ve Model objeleri başarıyla oluşturuldu. Eğitime başlamaya hazırsınız.\")"
      ],
      "metadata": {
        "id": "NsjSV-NFPKpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================\n",
        "# 5-7. ADIM: Dengeli Multi-label Eğitim, Kaydetme ve Test Değerlendirme\n",
        "# ======================================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# -------------------------------\n",
        "# 0. Varsayılan değişkenler\n",
        "# -------------------------------\n",
        "MODEL_NAME = \"dbmdz/bert-base-turkish-cased\"\n",
        "ANA_KATEGORILER = ['ÜCRET İADESİ','BAGAJ','MÜŞTERİ HİZMETLERİ','UYGULAMA/TEKNİK','RÖTAR']\n",
        "TEXT_COLUMN = 'temizlenmis_metin'\n",
        "MAX_LEN = 128\n",
        "TRAIN_BATCH = 8\n",
        "EVAL_BATCH = 8\n",
        "\n",
        "\n",
        "# Cihazı Belirle\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"\\n✅ Çalışma cihazı: {device}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Ağırlık kontrolü (sadece bilgi)\n",
        "# -------------------------------\n",
        "label_counts = train_df[ANA_KATEGORILER].sum()\n",
        "print(\"\\n✅ Artırma Sonrası Yeni Sınıf Sayımları (Dengeli Olmalı):\")\n",
        "print(label_counts.sort_values(ascending=False).to_string())\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Custom Trainer (Ağırlıksız Loss)\n",
        "# -------------------------------\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss_fct = nn.BCEWithLogitsLoss()  # pos_weight kaldırıldı\n",
        "        loss = loss_fct(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Dataset Sınıfı\n",
        "# -------------------------------\n",
        "class ComplaintDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.texts = texts.tolist()\n",
        "        self.labels = labels.values\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        encoding = self.tokenizer(\n",
        "            text, truncation=True, padding='max_length', max_length=self.max_len, return_tensors='pt'\n",
        "        )\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Tokenizer ve Dataset\n",
        "# -------------------------------\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
        "train_dataset = ComplaintDataset(train_df[TEXT_COLUMN], train_df[ANA_KATEGORILER], tokenizer, max_len=MAX_LEN)\n",
        "val_dataset = ComplaintDataset(val_df[TEXT_COLUMN], val_df[ANA_KATEGORILER], tokenizer, max_len=MAX_LEN)\n",
        "test_dataset = ComplaintDataset(test_df[TEXT_COLUMN], test_df[ANA_KATEGORILER], tokenizer, max_len=MAX_LEN)\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Model Yükleme\n",
        "# -------------------------------\n",
        "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(ANA_KATEGORILER))\n",
        "model.to(device)\n",
        "\n",
        "# -------------------------------\n",
        "# 6. Metrik Fonksiyonu\n",
        "# -------------------------------\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = torch.sigmoid(torch.tensor(pred.predictions)).numpy()\n",
        "    preds = (preds > 0.5).astype(int)\n",
        "    f1 = f1_score(labels, preds, average='micro')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"f1\": f1, \"accuracy\": acc}\n",
        "\n",
        "# -------------------------------\n",
        "# 7. Eğitim Parametreleri\n",
        "# -------------------------------\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/content/drive/MyDrive/BİTİRME/results',\n",
        "    num_train_epochs=12,\n",
        "    per_device_train_batch_size=TRAIN_BATCH,\n",
        "    per_device_eval_batch_size=EVAL_BATCH,\n",
        "    gradient_checkpointing=False,\n",
        "    logging_steps=50,\n",
        "    learning_rate=1e-5,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=False,\n",
        "    logging_dir='/content/drive/MyDrive/BİTİRME/logs',\n",
        "    report_to='none',\n",
        "    fp16=True if device.type=='cuda' else False\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 8. Trainer\n",
        "# -------------------------------\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 9. Eğitim Başlat\n",
        "# -------------------------------\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"BERT Model Eğitimi BAŞLIYOR... (Batch Size: {TRAIN_BATCH})\")\n",
        "print(\"=\"*50)\n",
        "trainer.train()\n",
        "\n",
        "# -------------------------------\n",
        "# 10. Model ve Tokenizer Kaydet\n",
        "# -------------------------------\n",
        "save_path = '/content/drive/MyDrive/BİTİRME/trained_bert_multi_label'\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n",
        "print(f\"\\n✅ Eğitim tamamlandı. Model ve tokenizer '{save_path}' klasörüne kaydedildi.\")\n",
        "\n",
        "# -------------------------------\n",
        "# 11. Test Seti Değerlendirme\n",
        "# -------------------------------\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"TEST SETİ ÜZERİNDE PERFORMANS DEĞERLENDİRMESİ\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "results = trainer.evaluate(test_dataset)\n",
        "print(\"\\n✅ Genel Test Metrikleri:\")\n",
        "print(results)\n",
        "\n",
        "# Tahminleri al\n",
        "predictions = trainer.predict(test_dataset)\n",
        "test_labels = predictions.label_ids\n",
        "test_preds = torch.sigmoid(torch.tensor(predictions.predictions)).numpy()\n",
        "test_preds_binary = (test_preds > 0.5).astype(int)\n",
        "\n",
        "print(\"\\n✅ Detaylı Sınıflandırma Raporu (Sınıf Bazlı Performans):\")\n",
        "print(classification_report(test_labels, test_preds_binary, target_names=ANA_KATEGORILER, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q0VsZLZpSaj8",
        "outputId": "e350e43f-f068-48a1-ed86-a4851b4c828b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Çalışma cihazı: cuda\n",
            "\n",
            "✅ Artırma Sonrası Yeni Sınıf Sayımları (Dengeli Olmalı):\n",
            "ÜCRET İADESİ          1487\n",
            "MÜŞTERİ HİZMETLERİ    1022\n",
            "BAGAJ                  967\n",
            "UYGULAMA/TEKNİK        966\n",
            "RÖTAR                  966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "BERT Model Eğitimi BAŞLIYOR... (Batch Size: 8)\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4716' max='4716' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4716/4716 05:39, Epoch 12/12]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.631000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.542500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.457600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.400900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.360900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.324300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.298500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.275300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.243000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.223900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.206300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.198200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.195300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.171500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.159100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.144100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.128300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.120800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.110700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.104400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.106700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.113500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.092000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.076900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.075100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.076400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.068900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.061400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.073400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.064400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.059400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.049300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.041400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.041600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.044700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.051900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.037800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.040100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.038700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.031200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>0.034100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.024500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>0.028300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.030200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.032900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.024900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>0.026200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.022100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>0.021900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.021400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>0.021200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.019700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2650</td>\n",
              "      <td>0.018300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.017200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>0.017900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.013900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2850</td>\n",
              "      <td>0.019800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.016200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2950</td>\n",
              "      <td>0.013400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.016100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3050</td>\n",
              "      <td>0.013500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.013500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3150</td>\n",
              "      <td>0.016800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.012900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3250</td>\n",
              "      <td>0.010900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.012100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3350</td>\n",
              "      <td>0.011800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.010600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3450</td>\n",
              "      <td>0.013600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.012700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3550</td>\n",
              "      <td>0.009500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3650</td>\n",
              "      <td>0.008400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.009700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3750</td>\n",
              "      <td>0.009500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.008800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3850</td>\n",
              "      <td>0.010200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.009400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3950</td>\n",
              "      <td>0.008800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.009700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4050</td>\n",
              "      <td>0.007900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.008600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4150</td>\n",
              "      <td>0.007600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.009100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4250</td>\n",
              "      <td>0.007600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.007900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4350</td>\n",
              "      <td>0.007000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.008400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4450</td>\n",
              "      <td>0.008500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.007000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4550</td>\n",
              "      <td>0.007300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.007600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4650</td>\n",
              "      <td>0.007100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.007600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Eğitim tamamlandı. Model ve tokenizer '/content/drive/MyDrive/BİTİRME/trained_bert_multi_label' klasörüne kaydedildi.\n",
            "\n",
            "==================================================\n",
            "TEST SETİ ÜZERİNDE PERFORMANS DEĞERLENDİRMESİ\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Genel Test Metrikleri:\n",
            "{'eval_loss': 0.3546130955219269, 'eval_f1': 0.8389057750759878, 'eval_accuracy': 0.6285714285714286, 'eval_runtime': 0.5806, 'eval_samples_per_second': 180.856, 'eval_steps_per_second': 24.114, 'epoch': 12.0}\n",
            "\n",
            "✅ Detaylı Sınıflandırma Raporu (Sınıf Bazlı Performans):\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "      ÜCRET İADESİ       0.84      0.86      0.85        59\n",
            "             BAGAJ       0.95      1.00      0.98        21\n",
            "MÜŞTERİ HİZMETLERİ       0.79      0.83      0.81        41\n",
            "   UYGULAMA/TEKNİK       0.79      0.72      0.75        32\n",
            "             RÖTAR       0.90      0.82      0.86        11\n",
            "\n",
            "         micro avg       0.84      0.84      0.84       164\n",
            "         macro avg       0.85      0.85      0.85       164\n",
            "      weighted avg       0.84      0.84      0.84       164\n",
            "       samples avg       0.86      0.86      0.84       164\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================\n",
        "# Performans Analizi: ROC, Confusion Matrix, Inference Time\n",
        "# ======================================================================\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report, roc_auc_score, roc_curve, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "\n",
        "# -------------------------------\n",
        "# 0. Model ve Tokenizer Yolu\n",
        "# -------------------------------\n",
        "model_path = '/content/drive/MyDrive/BİTİRME/trained_bert_multi_label'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Dataset Sınıfı\n",
        "# -------------------------------\n",
        "class ComplaintDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.texts = texts.tolist()\n",
        "        self.labels = labels.values\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        encoding = self.tokenizer(\n",
        "            text, truncation=True, padding='max_length', max_length=self.max_len, return_tensors='pt'\n",
        "        )\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Test Dataset ve DataLoader\n",
        "# -------------------------------\n",
        "test_dataset = ComplaintDataset(test_df[TEXT_COLUMN], test_df[ANA_KATEGORILER], tokenizer, max_len=MAX_LEN)\n",
        "test_loader = DataLoader(test_dataset, batch_size=EVAL_BATCH)\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Tahmin ve Inference Time\n",
        "# -------------------------------\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "start_time = time.time()\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs = {k: v.to(device) for k,v in batch.items() if k != 'labels'}\n",
        "        labels = batch['labels'].to(device)\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        probs = torch.sigmoid(logits)\n",
        "        all_preds.append(probs.cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "\n",
        "inference_time = time.time() - start_time\n",
        "print(f\"\\n✅ Toplam inference süresi: {inference_time:.4f} saniye\")\n",
        "\n",
        "all_preds = torch.cat(all_preds).numpy()\n",
        "all_labels = torch.cat(all_labels).numpy()\n",
        "all_preds_binary = (all_preds > 0.5).astype(int)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Genel ve Sınıf Bazlı Performans\n",
        "# -------------------------------\n",
        "f1_micro = f1_score(all_labels, all_preds_binary, average='micro')\n",
        "accuracy = accuracy_score(all_labels, all_preds_binary)\n",
        "print(f\"\\n✅ Genel F1 (micro): {f1_micro:.4f}\")\n",
        "print(f\"✅ Genel Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\n✅ Detaylı Sınıf Bazlı Rapor:\")\n",
        "print(classification_report(all_labels, all_preds_binary, target_names=ANA_KATEGORILER, zero_division=0))\n",
        "\n",
        "# -------------------------------\n",
        "# 5. ROC Eğrileri ve AUC\n",
        "# -------------------------------\n",
        "os.makedirs('/content/drive/MyDrive/BİTİRME/metrics', exist_ok=True)\n",
        "plt.figure(figsize=(10,8))\n",
        "\n",
        "for i, label in enumerate(ANA_KATEGORILER):\n",
        "    fpr, tpr, _ = roc_curve(all_labels[:,i], all_preds[:,i])\n",
        "    auc = roc_auc_score(all_labels[:,i], all_preds[:,i])\n",
        "    plt.plot(fpr, tpr, label=f\"{label} (AUC={auc:.2f})\")\n",
        "\n",
        "plt.plot([0,1],[0,1],'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Multi-label ROC Eğrileri')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "roc_path = '/content/drive/MyDrive/BİTİRME/metrics/roc_curves.png'\n",
        "plt.savefig(roc_path)\n",
        "plt.close()\n",
        "print(f\"\\n✅ ROC eğrileri kaydedildi: {roc_path}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 6. Confusion Matrix (Her Sınıf için)\n",
        "# -------------------------------\n",
        "cm_dir = '/content/drive/MyDrive/BİTİRME/metrics/confusion_matrices'\n",
        "os.makedirs(cm_dir, exist_ok=True)\n",
        "\n",
        "for i, label in enumerate(ANA_KATEGORILER):\n",
        "    cm = confusion_matrix(all_labels[:,i], all_preds_binary[:,i])\n",
        "    plt.figure(figsize=(4,4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "    plt.title(f'Confusion Matrix - {label}')\n",
        "    plt.xlabel('Tahmin')\n",
        "    plt.ylabel('Gerçek')\n",
        "    safe_label = label.replace(\"/\", \"_\").replace(\" \", \"_\")  # güvenli dosya adı\n",
        "    cm_path = os.path.join(cm_dir, f'confusion_{safe_label}.png')\n",
        "    plt.savefig(cm_path)\n",
        "    plt.close()\n",
        "    print(f\"✅ {label} confusion matrix kaydedildi: {cm_path}\")\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 7. Tüm metrikleri CSV olarak kaydet\n",
        "# -------------------------------\n",
        "metrics_df = pd.DataFrame({\n",
        "    'label': ANA_KATEGORILER,\n",
        "    'f1': [f1_score(all_labels[:,i], all_preds_binary[:,i]) for i in range(len(ANA_KATEGORILER))],\n",
        "    'accuracy': [accuracy_score(all_labels[:,i], all_preds_binary[:,i]) for i in range(len(ANA_KATEGORILER))],\n",
        "    'roc_auc': [roc_auc_score(all_labels[:,i], all_preds[:,i]) for i in range(len(ANA_KATEGORILER))]\n",
        "})\n",
        "metrics_path = '/content/drive/MyDrive/BİTİRME/metrics/per_class_metrics.csv'\n",
        "metrics_df.to_csv(metrics_path, index=False)\n",
        "print(f\"\\n✅ Sınıf bazlı metrikler kaydedildi: {metrics_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QawLjcWhWo3u",
        "outputId": "277527a8-ffe7-4d66-8451-1cf686a06c8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Toplam inference süresi: 0.4775 saniye\n",
            "\n",
            "✅ Genel F1 (micro): 0.8389\n",
            "✅ Genel Accuracy: 0.6286\n",
            "\n",
            "✅ Detaylı Sınıf Bazlı Rapor:\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "      ÜCRET İADESİ       0.84      0.86      0.85        59\n",
            "             BAGAJ       0.95      1.00      0.98        21\n",
            "MÜŞTERİ HİZMETLERİ       0.79      0.83      0.81        41\n",
            "   UYGULAMA/TEKNİK       0.79      0.72      0.75        32\n",
            "             RÖTAR       0.90      0.82      0.86        11\n",
            "\n",
            "         micro avg       0.84      0.84      0.84       164\n",
            "         macro avg       0.85      0.85      0.85       164\n",
            "      weighted avg       0.84      0.84      0.84       164\n",
            "       samples avg       0.86      0.86      0.84       164\n",
            "\n",
            "\n",
            "✅ ROC eğrileri kaydedildi: /content/drive/MyDrive/BİTİRME/metrics/roc_curves.png\n",
            "✅ ÜCRET İADESİ confusion matrix kaydedildi: /content/drive/MyDrive/BİTİRME/metrics/confusion_matrices/confusion_ÜCRET_İADESİ.png\n",
            "✅ BAGAJ confusion matrix kaydedildi: /content/drive/MyDrive/BİTİRME/metrics/confusion_matrices/confusion_BAGAJ.png\n",
            "✅ MÜŞTERİ HİZMETLERİ confusion matrix kaydedildi: /content/drive/MyDrive/BİTİRME/metrics/confusion_matrices/confusion_MÜŞTERİ_HİZMETLERİ.png\n",
            "✅ UYGULAMA/TEKNİK confusion matrix kaydedildi: /content/drive/MyDrive/BİTİRME/metrics/confusion_matrices/confusion_UYGULAMA_TEKNİK.png\n",
            "✅ RÖTAR confusion matrix kaydedildi: /content/drive/MyDrive/BİTİRME/metrics/confusion_matrices/confusion_RÖTAR.png\n",
            "\n",
            "✅ Sınıf bazlı metrikler kaydedildi: /content/drive/MyDrive/BİTİRME/metrics/per_class_metrics.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# 1. Adım: Drive'ı bağla ve veri yükle\n",
        "# ========================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import unicodedata\n",
        "import nltk\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "# ========================================================\n",
        "# 2. Ayarlar ve dosya yolu\n",
        "# ========================================================\n",
        "TEXT_COLUMN = 'temizlenmis_metin'\n",
        "ANA_KATEGORILER = ['ÜCRET İADESİ','BAGAJ','MÜŞTERİ HİZMETLERİ','UYGULAMA/TEKNİK','RÖTAR']\n",
        "\n",
        "DOSYA_ADI = '/content/drive/MyDrive/BİTİRME/Unlabeled_Data.xlsx'\n",
        "MODEL_DIR = '/content/drive/MyDrive/BİTİRME/trained_bert_multi_label'  # 1K veriden eğittiğin model\n",
        "SAVE_DIR = '/content/drive/MyDrive/BİTİRME'\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# ========================================================\n",
        "# 3. Veri yükleme\n",
        "# ========================================================\n",
        "df = pd.read_excel(DOSYA_ADI)\n",
        "df.columns = [col.strip().replace(' ', '').replace('İ', 'I') for col in df.columns]\n",
        "\n",
        "# Başlık ve içerik sütunlarını birleştir\n",
        "df['metin'] = df[['Baslik', 'Icerik']].fillna('').agg(' '.join, axis=1)\n",
        "\n",
        "# ========================================================\n",
        "# 4. Temizlik fonksiyonları\n",
        "# ========================================================\n",
        "stop_words_tr = set(nltk.corpus.stopwords.words('turkish'))\n",
        "ek_stop_words = {'rica', 'bilgi', 'olay', 'durum', 'yapmak', 'etmek', 'olmak',\n",
        "                 'süre', 'değil', 'gerekli', 'taraf', 'istemek', 'istiyorum', 'yapılmasını',\n",
        "                 'gerek', 'nedeniyle', 'a', 'o', 'bu', 'ki', 'için', 'ile', 've', 'ya', 'bir',\n",
        "                 'ben', 'sen', 'biz', 'siz'}\n",
        "stop_words_tr.update(ek_stop_words)\n",
        "\n",
        "def nlp_clean(text):\n",
        "    if pd.isna(text) or text is None: return \"\"\n",
        "    text = str(text).lower()\n",
        "    text = unicodedata.normalize('NFKC', text)\n",
        "    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
        "    text = re.sub(r'[\\d€$₺£]', ' ', text)\n",
        "    text = re.sub(r'\\s*\\S+@\\S+|\\s*https?://\\S+|\\s*www\\.\\S+', ' ', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    kelimeler = text.split()\n",
        "    kelimeler = [k for k in kelimeler if k not in stop_words_tr]\n",
        "    return \" \".join(kelimeler).strip()\n",
        "\n",
        "def fix_unicode(text):\n",
        "    replacements = {'i̇': 'i', 'I': 'ı', 'İ': 'i', 'Ö': 'ö', 'Ü': 'ü', 'Ç': 'ç', 'Ş': 'ş', 'Ğ': 'ğ'}\n",
        "    for wrong, correct in replacements.items():\n",
        "        text = text.replace(wrong, correct)\n",
        "    return text.strip()\n",
        "\n",
        "df[TEXT_COLUMN] = df['metin'].apply(nlp_clean).apply(fix_unicode)\n",
        "df = df[df[TEXT_COLUMN].str.split().str.len() > 3]\n",
        "\n",
        "print(f\"✅ Temizlik tamamlandı. Satır sayısı: {len(df)}\")\n",
        "\n",
        "# ========================================================\n",
        "# 5. Temizlenmiş veriyi kaydet\n",
        "# ========================================================\n",
        "cleaned_excel = os.path.join(SAVE_DIR, \"Unlabeled_Data_cleaned.xlsx\")\n",
        "df.to_excel(cleaned_excel, index=False)\n",
        "print(f\"✅ Temizlenmiş veri kaydedildi: {cleaned_excel}\")\n",
        "\n",
        "# ========================================================\n",
        "# 6. Otomatik etiketleme için DataSet ve DataLoader\n",
        "# ========================================================\n",
        "class PredictDataset(Dataset):\n",
        "    def __init__(self, texts, tokenizer, max_len=128):\n",
        "        self.texts = texts.tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_len,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "\n",
        "# ========================================================\n",
        "# 7. Model ve tokenizer yükle\n",
        "# ========================================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_DIR)\n",
        "model = BertForSequenceClassification.from_pretrained(MODEL_DIR)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# ========================================================\n",
        "# 8. Tahmin\n",
        "# ========================================================\n",
        "predict_dataset = PredictDataset(df[TEXT_COLUMN], tokenizer)\n",
        "predict_loader = DataLoader(predict_dataset, batch_size=32)\n",
        "\n",
        "all_preds = []\n",
        "with torch.no_grad():\n",
        "    for batch in predict_loader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        preds = torch.sigmoid(outputs.logits).cpu().numpy()\n",
        "        all_preds.append(preds)\n",
        "\n",
        "all_preds = np.vstack(all_preds)\n",
        "\n",
        "# ========================================================\n",
        "# 8b. Sınıf bazlı yüksek güven skoru (0.8) ile 0/1\n",
        "# ========================================================\n",
        "thresholds = {k: 0.8 for k in ANA_KATEGORILER}\n",
        "binary_preds = np.zeros_like(all_preds, dtype=int)\n",
        "for i, kategori in enumerate(ANA_KATEGORILER):\n",
        "    binary_preds[:, i] = (all_preds[:, i] >= thresholds[kategori]).astype(int)\n",
        "\n",
        "# ========================================================\n",
        "# 9. Tahminleri DataFrame'e ekle\n",
        "# ========================================================\n",
        "for i, kategori in enumerate(ANA_KATEGORILER):\n",
        "    df[kategori] = binary_preds[:, i]\n",
        "\n",
        "# ========================================================\n",
        "# 10. Kaydet\n",
        "# ========================================================\n",
        "auto_labeled_file = os.path.join(SAVE_DIR, \"Unlabeled_Data_auto_labeled.xlsx\")\n",
        "df.to_excel(auto_labeled_file, index=False)\n",
        "print(f\"✅ Otomatik etiketlenen veri kaydedildi: {auto_labeled_file}\")\n",
        "\n",
        "print(\"✅ İşlem tamamlandı.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHppYUJBjXTs",
        "outputId": "7c696d2f-0052-4d6d-fc3d-8b3016fb9b51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Temizlik tamamlandı. Satır sayısı: 22822\n",
            "✅ Temizlenmiş veri kaydedildi: /content/drive/MyDrive/BİTİRME/Unlabeled_Data_cleaned.xlsx\n",
            "✅ Otomatik etiketlenen veri kaydedildi: /content/drive/MyDrive/BİTİRME/Unlabeled_Data_auto_labeled.xlsx\n",
            "✅ İşlem tamamlandı.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# 0. GEREKLİ KÜTÜPHANELER VE DRIVE BAĞLANTISI\n",
        "# ========================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import unicodedata\n",
        "import nltk\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "# ========================================================\n",
        "# 1. AYARLAR VE DOSYA YOLLARI\n",
        "# ========================================================\n",
        "TEXT_COLUMN = 'temizlenmis_metin'\n",
        "ANA_KATEGORILER = ['ÜCRET İADESİ','BAGAJ','MÜŞTERİ HİZMETLERİ','UYGULAMA/TEKNİK','RÖTAR']\n",
        "\n",
        "DOSYA_ADI = '/content/drive/MyDrive/BİTİRME/Unlabeled_Data.xlsx'\n",
        "MODEL_DIR = '/content/drive/MyDrive/BİTİRME/trained_bert_multi_label'  # Önceden eğitilen model\n",
        "SAVE_DIR = '/content/drive/MyDrive/BİTİRME'\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# ========================================================\n",
        "# 2. VERİ YÜKLEME VE SÜTUN BİRLEŞTİRME\n",
        "# ========================================================\n",
        "df = pd.read_excel(DOSYA_ADI)\n",
        "df.columns = [col.strip().replace(' ', '').replace('İ', 'I') for col in df.columns]\n",
        "df['metin'] = df[['Baslik', 'Icerik']].fillna('').agg(' '.join, axis=1)\n",
        "\n",
        "# ========================================================\n",
        "# 3. TEMİZLİK FONKSİYONLARI\n",
        "# ========================================================\n",
        "stop_words_tr = set(nltk.corpus.stopwords.words('turkish'))\n",
        "ek_stop_words = {'rica', 'bilgi', 'olay', 'durum', 'yapmak', 'etmek', 'olmak',\n",
        "                 'süre', 'değil', 'gerekli', 'taraf', 'istemek', 'istiyorum', 'yapılmasını',\n",
        "                 'gerek', 'nedeniyle', 'a', 'o', 'bu', 'ki', 'için', 'ile', 've', 'ya', 'bir',\n",
        "                 'ben', 'sen', 'biz', 'siz'}\n",
        "stop_words_tr.update(ek_stop_words)\n",
        "\n",
        "def nlp_clean(text):\n",
        "    if pd.isna(text) or text is None: return \"\"\n",
        "    text = str(text).lower()\n",
        "    text = unicodedata.normalize('NFKC', text)\n",
        "    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
        "    text = re.sub(r'[\\d€$₺£]', ' ', text)\n",
        "    text = re.sub(r'\\s*\\S+@\\S+|\\s*https?://\\S+|\\s*www\\.\\S+', ' ', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    kelimeler = text.split()\n",
        "    kelimeler = [k for k in kelimeler if k not in stop_words_tr]\n",
        "    return \" \".join(kelimeler).strip()\n",
        "\n",
        "def fix_unicode(text):\n",
        "    replacements = {'i̇': 'i', 'I': 'ı', 'İ': 'i', 'Ö': 'ö', 'Ü': 'ü', 'Ç': 'ç', 'Ş': 'ş', 'Ğ': 'ğ'}\n",
        "    for wrong, correct in replacements.items():\n",
        "        text = text.replace(wrong, correct)\n",
        "    return text.strip()\n",
        "\n",
        "# ========================================================\n",
        "# 4. TEMİZLEME VE FİLTRELEME\n",
        "# ========================================================\n",
        "df[TEXT_COLUMN] = df['metin'].apply(nlp_clean).apply(fix_unicode)\n",
        "df = df[df[TEXT_COLUMN].str.split().str.len() > 3]\n",
        "\n",
        "cleaned_excel = os.path.join(SAVE_DIR, \"Unlabeled_Data_cleaned.xlsx\")\n",
        "df.to_excel(cleaned_excel, index=False)\n",
        "print(f\"✅ Temizlik tamamlandı. Satır sayısı: {len(df)}\")\n",
        "print(f\"✅ Temizlenmiş veri kaydedildi: {cleaned_excel}\")\n",
        "\n",
        "# ========================================================\n",
        "# 5. PREDICT DATASET VE DATALOADER\n",
        "# ========================================================\n",
        "class PredictDataset(Dataset):\n",
        "    def __init__(self, texts, tokenizer, max_len=128):\n",
        "        self.texts = texts.tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_len,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "\n",
        "# ========================================================\n",
        "# 6. MODEL VE TOKENIZER YÜKLEME\n",
        "# ========================================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_DIR)\n",
        "model = BertForSequenceClassification.from_pretrained(MODEL_DIR)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# ========================================================\n",
        "# 7. TAHMİN VE 0.8 EŞİK İLE OTOMATİK ETİKETLEME\n",
        "# ========================================================\n",
        "predict_dataset = PredictDataset(df[TEXT_COLUMN], tokenizer)\n",
        "predict_loader = DataLoader(predict_dataset, batch_size=32)\n",
        "\n",
        "all_preds = []\n",
        "with torch.no_grad():\n",
        "    for batch in predict_loader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        preds = torch.sigmoid(outputs.logits).cpu().numpy()\n",
        "        all_preds.append(preds)\n",
        "\n",
        "all_preds = np.vstack(all_preds)\n",
        "\n",
        "thresholds = {k: 0.8 for k in ANA_KATEGORILER}\n",
        "binary_preds = np.zeros_like(all_preds, dtype=int)\n",
        "for i, kategori in enumerate(ANA_KATEGORILER):\n",
        "    binary_preds[:, i] = (all_preds[:, i] >= thresholds[kategori]).astype(int)\n",
        "\n",
        "for i, kategori in enumerate(ANA_KATEGORILER):\n",
        "    df[kategori] = binary_preds[:, i]\n",
        "\n",
        "auto_labeled_file = os.path.join(SAVE_DIR, \"Unlabeled_Data_auto_labeled.xlsx\")\n",
        "df.to_excel(auto_labeled_file, index=False)\n",
        "print(f\"✅ Otomatik etiketlenen veri kaydedildi: {auto_labeled_file}\")\n",
        "\n",
        "# ========================================================\n",
        "# 8. YÜKSEK GÜVEN SKORUNA SAHİP VERİLERİ AYIRMA\n",
        "# ========================================================\n",
        "df_high_conf = df[(df[ANA_KATEGORILER] == 1).any(axis=1)]\n",
        "high_conf_file = os.path.join(SAVE_DIR, \"Unlabeled_Data_high_conf.xlsx\")\n",
        "df_high_conf.to_excel(high_conf_file, index=False)\n",
        "print(f\"✅ Yüksek güvenli veri kaydedildi: {high_conf_file}, satır sayısı: {len(df_high_conf)}\")\n",
        "\n",
        "# ========================================================\n",
        "# 9. ETİKETLİ VERİ İLE BİRLEŞTİRME\n",
        "# ========================================================\n",
        "labeled_file = os.path.join(SAVE_DIR, \"Labeled_Data.xlsx\")\n",
        "if os.path.exists(labeled_file):\n",
        "    df_labeled = pd.read_excel(labeled_file)\n",
        "    df_combined = pd.concat([df_labeled, df_high_conf], ignore_index=True)\n",
        "    combined_file = os.path.join(SAVE_DIR, \"Combined_Labeled_Data.xlsx\")\n",
        "    df_combined.to_excel(combined_file, index=False)\n",
        "    print(f\"✅ Birleştirilmiş veri kaydedildi: {combined_file}, toplam satır sayısı: {len(df_combined)}\")\n",
        "else:\n",
        "    print(\"⚠️ Labeled_Data.xlsx bulunamadı, birleştirme atlandı.\")\n",
        "\n",
        "print(\"\\n🎯 TÜM İŞLEM BAŞARIYLA TAMAMLANDI 🎯\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfflr4FvmY64",
        "outputId": "d1b1e502-4cda-40fc-bc95-db98a53f8b95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Temizlik tamamlandı. Satır sayısı: 22822\n",
            "✅ Temizlenmiş veri kaydedildi: /content/drive/MyDrive/BİTİRME/Unlabeled_Data_cleaned.xlsx\n",
            "✅ Otomatik etiketlenen veri kaydedildi: /content/drive/MyDrive/BİTİRME/Unlabeled_Data_auto_labeled.xlsx\n",
            "✅ Yüksek güvenli veri kaydedildi: /content/drive/MyDrive/BİTİRME/Unlabeled_Data_high_conf.xlsx, satır sayısı: 22546\n",
            "✅ Birleştirilmiş veri kaydedildi: /content/drive/MyDrive/BİTİRME/Combined_Labeled_Data.xlsx, toplam satır sayısı: 23598\n",
            "\n",
            "🎯 TÜM İŞLEM BAŞARIYLA TAMAMLANDI 🎯\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1️⃣ Veri yükleme\n",
        "path = \"/content/drive/MyDrive/BİTİRME/Unlabeled_Data_high_conf.xlsx\"\n",
        "df = pd.read_excel(path)\n",
        "\n",
        "# 2️⃣ Sütunları kontrol et\n",
        "print(\"✅ Sütunlar:\", df.columns.tolist())\n",
        "\n",
        "# 3️⃣ En yüksek olasılığa sahip sütunu etiket olarak belirle\n",
        "etiket_sutunlari = ['ÜCRET İADESİ', 'BAGAJ', 'MÜŞTERİ HİZMETLERİ', 'UYGULAMA/TEKNİK', 'RÖTAR']\n",
        "\n",
        "# En yüksek değeri alan sütunu predicted_label yap\n",
        "df['predicted_label'] = df[etiket_sutunlari].idxmax(axis=1)\n",
        "\n",
        "# 4️⃣ Sınıf dağılımı\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.countplot(x='predicted_label', data=df, order=df['predicted_label'].value_counts().index)\n",
        "plt.title(\"Sınıf Dağılımı (Yüksek Güvenli Veri)\")\n",
        "plt.xlabel(\"Etiket\")\n",
        "plt.ylabel(\"Adet\")\n",
        "plt.show()\n",
        "\n",
        "# 5️⃣ Kontrol\n",
        "df['predicted_label'].value_counts()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761
        },
        "id": "AXGwWESQ6_M4",
        "outputId": "fa8a8c61-0071-4bc6-8e7d-43c4c4157c46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Sütunlar: ['Baslik', 'Icerik', 'metin', 'temizlenmis_metin', 'ÜCRET İADESİ', 'BAGAJ', 'MÜŞTERİ HİZMETLERİ', 'UYGULAMA/TEKNİK', 'RÖTAR']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "predicted_label\n",
              "ÜCRET İADESİ          10009\n",
              "BAGAJ                  4832\n",
              "MÜŞTERİ HİZMETLERİ     4515\n",
              "UYGULAMA/TEKNİK        2093\n",
              "RÖTAR                  1097\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>predicted_label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ÜCRET İADESİ</th>\n",
              "      <td>10009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BAGAJ</th>\n",
              "      <td>4832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MÜŞTERİ HİZMETLERİ</th>\n",
              "      <td>4515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>UYGULAMA/TEKNİK</th>\n",
              "      <td>2093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RÖTAR</th>\n",
              "      <td>1097</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyVHkJRaPLxO",
        "outputId": "432e5676-1bdc-45e0-8347-225cee2d1418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# 1️⃣ Kütüphaneler\n",
        "# ========================================================\n",
        "!pip install deep-translator -q\n",
        "from deep_translator import GoogleTranslator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "# ========================================================\n",
        "# 2️⃣ Yüksek güvenli veriyi oku\n",
        "# ========================================================\n",
        "df = pd.read_excel(\"/content/drive/MyDrive/BİTİRME/Unlabeled_Data_high_conf.xlsx\")\n",
        "\n",
        "# Hedef sınıflar ve kaç örnek istiyoruz (örnek: her sınıf 5000'e tamamlanacak)\n",
        "target_counts = {\n",
        "    'RÖTAR': 4000\n",
        "}\n",
        "\n",
        "TEXT_COLUMN = 'temizlenmis_metin'\n",
        "\n",
        "# ========================================================\n",
        "# 3️⃣ Back-Translation ile veri artırma\n",
        "# ========================================================\n",
        "def back_translate(text, src='tr', tmp='en', trg='tr'):\n",
        "    try:\n",
        "        translated = GoogleTranslator(source=src, target=tmp).translate(text)\n",
        "        back_translated = GoogleTranslator(source=tmp, target=trg).translate(translated)\n",
        "        return back_translated\n",
        "    except:\n",
        "        return text  # hata olursa orijinalini döndür\n",
        "\n",
        "augmented_rows = []\n",
        "\n",
        "for col, target_count in target_counts.items():\n",
        "    current_rows = df[df[col]==1]\n",
        "    n_current = len(current_rows)\n",
        "    n_to_generate = target_count - n_current\n",
        "    print(f\"{col}: mevcut={n_current}, üretilecek={n_to_generate}\")\n",
        "\n",
        "    if n_to_generate > 0:\n",
        "        for _ in tqdm(range(n_to_generate)):\n",
        "            row = current_rows.sample(1).iloc[0]\n",
        "            new_text = back_translate(row[TEXT_COLUMN])\n",
        "\n",
        "            # yeni satır oluştur\n",
        "            new_row = row.copy()\n",
        "            new_row[TEXT_COLUMN] = new_text\n",
        "            augmented_rows.append(new_row)\n",
        "\n",
        "# ========================================================\n",
        "# 4️⃣ Oluşturulan satırları DataFrame’e ekle\n",
        "# ========================================================\n",
        "if augmented_rows:\n",
        "    df_augmented = pd.DataFrame(augmented_rows)\n",
        "    df_combined = pd.concat([df, df_augmented], ignore_index=True)\n",
        "else:\n",
        "    df_combined = df.copy()\n",
        "\n",
        "print(f\"✅ Toplam satır sayısı: {len(df_combined)}\")\n",
        "\n",
        "# ========================================================\n",
        "# 5️⃣ Kaydet\n",
        "# ========================================================\n",
        "df_combined.to_excel(\"/content/drive/MyDrive/BİTİRME/HighConf_BackTranslated.xlsx\", index=False)\n",
        "print(\"✅ Back-translation ile artırılmış veri kaydedildi.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvkEKBt8k767",
        "outputId": "4bcaac61-a926-47e5-bd35-34db6941acb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RÖTAR: mevcut=2734, üretilecek=1266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 21/1266 [00:16<20:54,  1.01s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81IISCd0ut7T",
        "outputId": "1a4e325a-ed9f-4d78-b043-4aa13c7a3b4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openpyxl -q\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oH4mYr7vNJ_",
        "outputId": "f141612f-092c-49e5-beaf-fdbf7bb9405c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/250.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.9/250.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Dosya yolu\n",
        "file_path = \"/content/drive/MyDrive/BİTİRME/HighConf_BackTranslated.xlsx\"\n",
        "\n",
        "# Dosyayı oku\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Toplam satır sayısı\n",
        "print(f\"✅ Satır sayısı: {len(df)}\")\n",
        "\n",
        "# Sütunları ve sınıf sütunlarını kontrol et\n",
        "print(f\"✅ Sütunlar: {df.columns.tolist()}\")\n",
        "\n",
        "# Sınıf dağılımı\n",
        "class_cols = ['RÖTAR', 'UYGULAMA/TEKNİK', 'BAGAJ', 'ÜCRET İADESİ', 'MÜŞTERİ HİZMETLERİ']\n",
        "for col in class_cols:\n",
        "    if col in df.columns:\n",
        "        print(f\"{col}: {df[col].sum()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIoGDp_MtO5Z",
        "outputId": "726f7d21-2df4-4edc-d16f-a57ff66aa04f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Satır sayısı: 23812\n",
            "✅ Sütunlar: ['Baslik', 'Icerik', 'metin', 'temizlenmis_metin', 'ÜCRET İADESİ', 'BAGAJ', 'MÜŞTERİ HİZMETLERİ', 'UYGULAMA/TEKNİK', 'RÖTAR']\n",
            "RÖTAR: 4000\n",
            "UYGULAMA/TEKNİK: 5188\n",
            "BAGAJ: 5902\n",
            "ÜCRET İADESİ: 10698\n",
            "MÜŞTERİ HİZMETLERİ: 7984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# 1️⃣ Kütüphaneler\n",
        "# ========================================================\n",
        "!pip install deep-translator -q\n",
        "from deep_translator import GoogleTranslator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "# ========================================================\n",
        "# 2️⃣ Yüksek güvenli veriyi oku\n",
        "# ========================================================\n",
        "df = pd.read_excel(\"/content/drive/MyDrive/BİTİRME/HighConf_BackTranslated.xlsx\")\n",
        "\n",
        "# Hedef sınıflar ve kaç örnek istiyoruz (örnek: her sınıf 5000'e tamamlanacak)\n",
        "target_counts = {\n",
        "    'RÖTAR': 7500\n",
        "}\n",
        "\n",
        "TEXT_COLUMN = 'temizlenmis_metin'\n",
        "\n",
        "# ========================================================\n",
        "# 3️⃣ Back-Translation ile veri artırma\n",
        "# ========================================================\n",
        "def back_translate(text, src='tr', tmp='en', trg='tr'):\n",
        "    try:\n",
        "        translated = GoogleTranslator(source=src, target=tmp).translate(text)\n",
        "        back_translated = GoogleTranslator(source=tmp, target=trg).translate(translated)\n",
        "        return back_translated\n",
        "    except:\n",
        "        return text  # hata olursa orijinalini döndür\n",
        "\n",
        "augmented_rows = []\n",
        "\n",
        "for col, target_count in target_counts.items():\n",
        "    current_rows = df[df[col]==1]\n",
        "    n_current = len(current_rows)\n",
        "    n_to_generate = target_count - n_current\n",
        "    print(f\"{col}: mevcut={n_current}, üretilecek={n_to_generate}\")\n",
        "\n",
        "    if n_to_generate > 0:\n",
        "        for _ in tqdm(range(n_to_generate)):\n",
        "            row = current_rows.sample(1).iloc[0]\n",
        "            new_text = back_translate(row[TEXT_COLUMN])\n",
        "\n",
        "            # yeni satır oluştur\n",
        "            new_row = row.copy()\n",
        "            new_row[TEXT_COLUMN] = new_text\n",
        "            augmented_rows.append(new_row)\n",
        "\n",
        "# ========================================================\n",
        "# 4️⃣ Oluşturulan satırları DataFrame’e ekle\n",
        "# ========================================================\n",
        "if augmented_rows:\n",
        "    df_augmented = pd.DataFrame(augmented_rows)\n",
        "    df_combined = pd.concat([df, df_augmented], ignore_index=True)\n",
        "else:\n",
        "    df_combined = df.copy()\n",
        "\n",
        "print(f\"✅ Toplam satır sayısı: {len(df_combined)}\")\n",
        "\n",
        "# ========================================================\n",
        "# 5️⃣ Kaydet\n",
        "# ========================================================\n",
        "df_combined.to_excel(\"/content/drive/MyDrive/BİTİRME/HighConf_BackTranslated_p2.xlsx\", index=False)\n",
        "print(\"✅ Back-translation ile artırılmış veri kaydedildi.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axUB9QtuwMY3",
        "outputId": "1f0cbd38-88c2-4e4c-b7de-2b22e3745a89"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRÖTAR: mevcut=4000, üretilecek=3500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3500/3500 [36:01<00:00,  1.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Toplam satır sayısı: 27312\n",
            "✅ Back-translation ile artırılmış veri kaydedildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# 1️⃣ Kütüphaneler\n",
        "# ========================================================\n",
        "!pip install deep-translator -q\n",
        "from deep_translator import GoogleTranslator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "# ========================================================\n",
        "# 2️⃣ Yüksek güvenli veriyi oku\n",
        "# ========================================================\n",
        "df = pd.read_excel(\"/content/drive/MyDrive/BİTİRME/HighConf_BackTranslated_p2.xlsx\")\n",
        "\n",
        "# Hedef sınıflar ve kaç örnek istiyoruz (örnek: her sınıf 5000'e tamamlanacak)\n",
        "target_counts = {\n",
        "    'BAGAJ': 7500\n",
        "}\n",
        "\n",
        "TEXT_COLUMN = 'temizlenmis_metin'\n",
        "\n",
        "# ========================================================\n",
        "# 3️⃣ Back-Translation ile veri artırma\n",
        "# ========================================================\n",
        "def back_translate(text, src='tr', tmp='en', trg='tr'):\n",
        "    try:\n",
        "        translated = GoogleTranslator(source=src, target=tmp).translate(text)\n",
        "        back_translated = GoogleTranslator(source=tmp, target=trg).translate(translated)\n",
        "        return back_translated\n",
        "    except:\n",
        "        return text  # hata olursa orijinalini döndür\n",
        "\n",
        "augmented_rows = []\n",
        "\n",
        "for col, target_count in target_counts.items():\n",
        "    current_rows = df[df[col]==1]\n",
        "    n_current = len(current_rows)\n",
        "    n_to_generate = target_count - n_current\n",
        "    print(f\"{col}: mevcut={n_current}, üretilecek={n_to_generate}\")\n",
        "\n",
        "    if n_to_generate > 0:\n",
        "        for _ in tqdm(range(n_to_generate)):\n",
        "            row = current_rows.sample(1).iloc[0]\n",
        "            new_text = back_translate(row[TEXT_COLUMN])\n",
        "\n",
        "            # yeni satır oluştur\n",
        "            new_row = row.copy()\n",
        "            new_row[TEXT_COLUMN] = new_text\n",
        "            augmented_rows.append(new_row)\n",
        "\n",
        "# ========================================================\n",
        "# 4️⃣ Oluşturulan satırları DataFrame’e ekle\n",
        "# ========================================================\n",
        "if augmented_rows:\n",
        "    df_augmented = pd.DataFrame(augmented_rows)\n",
        "    df_combined = pd.concat([df, df_augmented], ignore_index=True)\n",
        "else:\n",
        "    df_combined = df.copy()\n",
        "\n",
        "print(f\"✅ Toplam satır sayısı: {len(df_combined)}\")\n",
        "\n",
        "# ========================================================\n",
        "# 5️⃣ Kaydet\n",
        "# ========================================================\n",
        "df_combined.to_excel(\"/content/drive/MyDrive/BİTİRME/HighConf_BackTranslated_p3.xlsx\", index=False)\n",
        "print(\"✅ Back-translation ile artırılmış veri kaydedildi.\")\n"
      ],
      "metadata": {
        "id": "VkvliAxd4ov2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28a062e6-22c2-47ab-c747-6f0ab91fde65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BAGAJ: mevcut=5922, üretilecek=1578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1578/1578 [17:37<00:00,  1.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Toplam satır sayısı: 28890\n",
            "✅ Back-translation ile artırılmış veri kaydedildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# 1️⃣ Kütüphaneler\n",
        "# ========================================================\n",
        "!pip install deep-translator -q\n",
        "from deep_translator import GoogleTranslator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "# ========================================================\n",
        "# 2️⃣ Yüksek güvenli veriyi oku\n",
        "# ========================================================\n",
        "df = pd.read_excel(\"/content/drive/MyDrive/BİTİRME/HighConf_BackTranslated_p3.xlsx\")\n",
        "\n",
        "# Hedef sınıflar ve kaç örnek istiyoruz (örnek: her sınıf 5000'e tamamlanacak)\n",
        "target_counts = {\n",
        "    'UYGULAMA/TEKNİK': 7500\n",
        "}\n",
        "\n",
        "TEXT_COLUMN = 'temizlenmis_metin'\n",
        "\n",
        "# ========================================================\n",
        "# 3️⃣ Back-Translation ile veri artırma\n",
        "# ========================================================\n",
        "def back_translate(text, src='tr', tmp='en', trg='tr'):\n",
        "    try:\n",
        "        translated = GoogleTranslator(source=src, target=tmp).translate(text)\n",
        "        back_translated = GoogleTranslator(source=tmp, target=trg).translate(translated)\n",
        "        return back_translated\n",
        "    except:\n",
        "        return text  # hata olursa orijinalini döndür\n",
        "\n",
        "augmented_rows = []\n",
        "\n",
        "for col, target_count in target_counts.items():\n",
        "    current_rows = df[df[col]==1]\n",
        "    n_current = len(current_rows)\n",
        "    n_to_generate = target_count - n_current\n",
        "    print(f\"{col}: mevcut={n_current}, üretilecek={n_to_generate}\")\n",
        "\n",
        "    if n_to_generate > 0:\n",
        "        for _ in tqdm(range(n_to_generate)):\n",
        "            row = current_rows.sample(1).iloc[0]\n",
        "            new_text = back_translate(row[TEXT_COLUMN])\n",
        "\n",
        "            # yeni satır oluştur\n",
        "            new_row = row.copy()\n",
        "            new_row[TEXT_COLUMN] = new_text\n",
        "            augmented_rows.append(new_row)\n",
        "\n",
        "# ========================================================\n",
        "# 4️⃣ Oluşturulan satırları DataFrame’e ekle\n",
        "# ========================================================\n",
        "if augmented_rows:\n",
        "    df_augmented = pd.DataFrame(augmented_rows)\n",
        "    df_combined = pd.concat([df, df_augmented], ignore_index=True)\n",
        "else:\n",
        "    df_combined = df.copy()\n",
        "\n",
        "print(f\"✅ Toplam satır sayısı: {len(df_combined)}\")\n",
        "\n",
        "# ========================================================\n",
        "# 5️⃣ Kaydet\n",
        "# ========================================================\n",
        "df_combined.to_excel(\"/content/drive/MyDrive/BİTİRME/HighConf_BackTranslated_p4.xlsx\", index=False)\n",
        "print(\"✅ Back-translation ile artırılmış veri kaydedildi.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goFGx-SI9QPs",
        "outputId": "3781d911-90c0-4992-f34b-afa1e18f0a3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UYGULAMA/TEKNİK: mevcut=5368, üretilecek=2132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2132/2132 [27:58<00:00,  1.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Toplam satır sayısı: 31022\n",
            "✅ Back-translation ile artırılmış veri kaydedildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ========================================================\n",
        "# 1️⃣ Veri yükle\n",
        "# ========================================================\n",
        "df = pd.read_excel(\"/content/drive/MyDrive/BİTİRME/HighConf_BackTranslated_p4.xlsx\")\n",
        "\n",
        "etiketler = ['ÜCRET İADESİ', 'BAGAJ', 'MÜŞTERİ HİZMETLERİ', 'UYGULAMA/TEKNİK', 'RÖTAR']\n",
        "\n",
        "# ========================================================\n",
        "# 2️⃣ Hedefler\n",
        "# ========================================================\n",
        "hedefler = {\n",
        "    'ÜCRET İADESİ': 8000\n",
        "    # MÜŞTERİ HİZMETLERİ'ni artık azaltmayacağız\n",
        "}\n",
        "\n",
        "# ========================================================\n",
        "# 3️⃣ Multi-etiketli satırları koru\n",
        "# ========================================================\n",
        "korunacak = (df['BAGAJ'] == 1) | (df['RÖTAR'] == 1) | (df['UYGULAMA/TEKNİK'] == 1)\n",
        "df_korunan = df[korunacak].copy()\n",
        "df_azalt = df[~korunacak].copy()\n",
        "\n",
        "print(f\"Korunan satır sayısı: {len(df_korunan)}\")\n",
        "print(f\"Azaltılabilir satır sayısı: {len(df_azalt)}\")\n",
        "\n",
        "# ========================================================\n",
        "# 4️⃣ Sadece ÜCRET İADESİ azalt\n",
        "# ========================================================\n",
        "etiket = 'ÜCRET İADESİ'\n",
        "hedef = hedefler[etiket]\n",
        "mevcut = int(df[df[etiket] == 1].shape[0])\n",
        "\n",
        "if mevcut > hedef:\n",
        "    fazla_sayi = mevcut - hedef\n",
        "    adaylar = df_azalt[df_azalt[etiket] == 1]\n",
        "    print(f\"\\n{etiket}: mevcut={mevcut}, azaltılacak={fazla_sayi}\")\n",
        "\n",
        "    if len(adaylar) > fazla_sayi:\n",
        "        silinecek = adaylar.sample(n=fazla_sayi, random_state=42)\n",
        "        df_azalt = df_azalt.drop(silinecek.index)\n",
        "    else:\n",
        "        print(\"⚠️ Yeterli tek etiketli aday yok, mümkün olan kadar azaltılacak.\")\n",
        "\n",
        "# ========================================================\n",
        "# 5️⃣ Sonuç birleştir\n",
        "# ========================================================\n",
        "son_df = pd.concat([df_korunan, df_azalt], ignore_index=True)\n",
        "\n",
        "print(\"\\n✅ Yeni etiket dağılımı:\")\n",
        "print(son_df[etiketler].sum())\n",
        "print(f\"✅ Toplam satır sayısı: {len(son_df)}\")\n",
        "\n",
        "# ========================================================\n",
        "# 6️⃣ Kaydet\n",
        "# ========================================================\n",
        "output_path = \"/content/drive/MyDrive/BİTİRME/HighConf_Reduced_p7.xlsx\"\n",
        "son_df.to_excel(output_path, index=False)\n",
        "print(f\"\\n✅ Kaydedildi: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0XLS1Q-_saU",
        "outputId": "ab61c1e7-4028-4e9d-c6e0-a8f5feb98d26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Korunan satır sayısı: 21683\n",
            "Azaltılabilir satır sayısı: 9339\n",
            "\n",
            "ÜCRET İADESİ: mevcut=13465, azaltılacak=5465\n",
            "\n",
            "✅ Yeni etiket dağılımı:\n",
            "ÜCRET İADESİ          8000\n",
            "BAGAJ                 7811\n",
            "MÜŞTERİ HİZMETLERİ    6673\n",
            "UYGULAMA/TEKNİK       7500\n",
            "RÖTAR                 7513\n",
            "dtype: int64\n",
            "✅ Toplam satır sayısı: 25557\n",
            "\n",
            "✅ Kaydedildi: /content/drive/MyDrive/BİTİRME/HighConf_Reduced_p7.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxImZtxhIZ2_",
        "outputId": "996dd593-824b-41a0-aa58-8e65979eff72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# 0️⃣ Kütüphaneler\n",
        "# =====================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# =====================================================\n",
        "# 1️⃣ Dosyaları yükle\n",
        "# =====================================================\n",
        "train_1k = pd.read_excel(\"/content/drive/MyDrive/BİTİRME/train_augmented_multi_label_balanced.xlsx\")\n",
        "high_conf = pd.read_excel(\"/content/drive/MyDrive/BİTİRME/HighConf_Reduced_p7.xlsx\")\n",
        "\n",
        "# =====================================================\n",
        "# 2️⃣ Gereksiz sütunları temizle\n",
        "# =====================================================\n",
        "for df in [train_1k, high_conf]:\n",
        "    if 'Baslik' in df.columns: df.drop(columns=['Baslik'], inplace=True)\n",
        "    if 'Icerik' in df.columns: df.drop(columns=['Icerik'], inplace=True)\n",
        "\n",
        "TEXT_COLUMN = 'temizlenmis_metin'\n",
        "ANA_KATEGORILER = ['ÜCRET İADESİ','BAGAJ','MÜŞTERİ HİZMETLERİ','UYGULAMA/TEKNİK','RÖTAR']\n",
        "\n",
        "# =====================================================\n",
        "# 3️⃣ 1k modeli warm-start olarak yükle\n",
        "# =====================================================\n",
        "MODEL_PATH_1K = '/content/drive/MyDrive/BİTİRME/trained_bert_multi_label'\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_PATH_1K)\n",
        "model = BertForSequenceClassification.from_pretrained(MODEL_PATH_1K, num_labels=len(ANA_KATEGORILER))\n",
        "\n",
        "# =====================================================\n",
        "# 4️⃣ High-conf ve 1k veriyi birleştir\n",
        "# =====================================================\n",
        "combined_df = pd.concat([train_1k, high_conf], ignore_index=True)\n",
        "texts = combined_df[TEXT_COLUMN]\n",
        "labels = combined_df[ANA_KATEGORILER]\n",
        "\n",
        "# =====================================================\n",
        "# 5️⃣ Dataset sınıfı\n",
        "# =====================================================\n",
        "class ComplaintDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.texts = texts.tolist()\n",
        "        self.labels = labels.values\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        encoding = self.tokenizer(\n",
        "            text, truncation=True, padding='max_length', max_length=self.max_len, return_tensors='pt'\n",
        "        )\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "dataset = ComplaintDataset(texts, labels, tokenizer)\n",
        "val_size = int(0.1*len(dataset))\n",
        "train_size = len(dataset) - val_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# =====================================================\n",
        "# 6️⃣ Custom Trainer\n",
        "# =====================================================\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss_fct = nn.BCEWithLogitsLoss()\n",
        "        loss = loss_fct(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = torch.sigmoid(torch.tensor(pred.predictions)).numpy()\n",
        "    preds_binary = (preds > 0.5).astype(int)\n",
        "    f1 = f1_score(labels, preds_binary, average='micro')\n",
        "    acc = accuracy_score(labels, preds_binary)\n",
        "    return {\"f1\": f1, \"accuracy\": acc}\n",
        "\n",
        "# =====================================================\n",
        "# 7️⃣ Eğitim parametreleri ve cihaz\n",
        "# =====================================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/content/drive/MyDrive/BİTİRME/results_finetune',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    learning_rate=1e-5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='/content/drive/MyDrive/BİTİRME/logs_finetune',\n",
        "    logging_steps=50,\n",
        "    report_to='none',\n",
        "    fp16=True if device.type=='cuda' else False\n",
        ")\n",
        "\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# =====================================================\n",
        "# 8️⃣ Fine-tune başlat\n",
        "# =====================================================\n",
        "print(\"\\n✅ Fine-tune başlatılıyor...\")\n",
        "trainer.train()\n",
        "\n",
        "# =====================================================\n",
        "# 9️⃣ Model ve tokenizer kaydet\n",
        "# =====================================================\n",
        "save_path = '/content/drive/MyDrive/BİTİRME/trained_bert_finetuned'\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n",
        "print(f\"\\n✅ Fine-tuned model ve tokenizer '{save_path}' klasörüne kaydedildi.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CUGDV1g2AGAG",
        "outputId": "56cdc37f-35fb-4bd4-a685-ae59e54a12c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Fine-tune başlatılıyor...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16145' max='16145' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16145/16145 18:26, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.090200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.065400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.067300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.057000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.069200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.077100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.053200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.089000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.066100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.067300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.066400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.051300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.047200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.048700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.059200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.035600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.070900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.061400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.063300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.058000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.051200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.080500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.056400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.051000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.060800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.043900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.055200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.058700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.045300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.050600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.053000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.048200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.062800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.068800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.065700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.054200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.060000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.050800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.057400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.056800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>0.048700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.041900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>0.035000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.050800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.068400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.052400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>0.046300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.039700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>0.072900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.049600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>0.036900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.053400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2650</td>\n",
              "      <td>0.034500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.070300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>0.049000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.053600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2850</td>\n",
              "      <td>0.028500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.041600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2950</td>\n",
              "      <td>0.078300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.057900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3050</td>\n",
              "      <td>0.055100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.041800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3150</td>\n",
              "      <td>0.040600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.037000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3250</td>\n",
              "      <td>0.036900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.018000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3350</td>\n",
              "      <td>0.022100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.023100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3450</td>\n",
              "      <td>0.031400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.018600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3550</td>\n",
              "      <td>0.019200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.031200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3650</td>\n",
              "      <td>0.025900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.027600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3750</td>\n",
              "      <td>0.029800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.021400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3850</td>\n",
              "      <td>0.032100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.041700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3950</td>\n",
              "      <td>0.022800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.034500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4050</td>\n",
              "      <td>0.030400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.027200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4150</td>\n",
              "      <td>0.035500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.022200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4250</td>\n",
              "      <td>0.026000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.018900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4350</td>\n",
              "      <td>0.044200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.034800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4450</td>\n",
              "      <td>0.035900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.028500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4550</td>\n",
              "      <td>0.029400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.028000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4650</td>\n",
              "      <td>0.035000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.026800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4750</td>\n",
              "      <td>0.030200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.038400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4850</td>\n",
              "      <td>0.031900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.028800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4950</td>\n",
              "      <td>0.033200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.030100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5050</td>\n",
              "      <td>0.027300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.036100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5150</td>\n",
              "      <td>0.032700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.018700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5250</td>\n",
              "      <td>0.030400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.033900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5350</td>\n",
              "      <td>0.028300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.015900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5450</td>\n",
              "      <td>0.023300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.019500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5550</td>\n",
              "      <td>0.026000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.034600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5650</td>\n",
              "      <td>0.018500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.026600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5750</td>\n",
              "      <td>0.021000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.026400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5850</td>\n",
              "      <td>0.023000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.018900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5950</td>\n",
              "      <td>0.018300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.032000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6050</td>\n",
              "      <td>0.022200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.023400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6150</td>\n",
              "      <td>0.020400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.010800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6250</td>\n",
              "      <td>0.021000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.023300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6350</td>\n",
              "      <td>0.026900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.033100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6450</td>\n",
              "      <td>0.027100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.006600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6550</td>\n",
              "      <td>0.027000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.014900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6650</td>\n",
              "      <td>0.015100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.026400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6750</td>\n",
              "      <td>0.014000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.009000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6850</td>\n",
              "      <td>0.017000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.012700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6950</td>\n",
              "      <td>0.010700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.017800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7050</td>\n",
              "      <td>0.023500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.012700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7150</td>\n",
              "      <td>0.014100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.012500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7250</td>\n",
              "      <td>0.009300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.007100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7350</td>\n",
              "      <td>0.011400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.016100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7450</td>\n",
              "      <td>0.017700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.005800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7550</td>\n",
              "      <td>0.025600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.008500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7650</td>\n",
              "      <td>0.014800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.013400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7750</td>\n",
              "      <td>0.016500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.022200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7850</td>\n",
              "      <td>0.015300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.012400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7950</td>\n",
              "      <td>0.017400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.013100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8050</td>\n",
              "      <td>0.020400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.015500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8150</td>\n",
              "      <td>0.017900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.020300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8250</td>\n",
              "      <td>0.011100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.018300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8350</td>\n",
              "      <td>0.017300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.016500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8450</td>\n",
              "      <td>0.013600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.008100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8550</td>\n",
              "      <td>0.013200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.023600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8650</td>\n",
              "      <td>0.017800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>0.021300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8750</td>\n",
              "      <td>0.009300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.016600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8850</td>\n",
              "      <td>0.021500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8900</td>\n",
              "      <td>0.009300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8950</td>\n",
              "      <td>0.019100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.017200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9050</td>\n",
              "      <td>0.010700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9100</td>\n",
              "      <td>0.016700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9150</td>\n",
              "      <td>0.016200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.016200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9250</td>\n",
              "      <td>0.015100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9300</td>\n",
              "      <td>0.012200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9350</td>\n",
              "      <td>0.007100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.015800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9450</td>\n",
              "      <td>0.007900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.014200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9550</td>\n",
              "      <td>0.015000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9600</td>\n",
              "      <td>0.022800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9650</td>\n",
              "      <td>0.004900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9700</td>\n",
              "      <td>0.006800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9750</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9800</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9850</td>\n",
              "      <td>0.010900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9900</td>\n",
              "      <td>0.002400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9950</td>\n",
              "      <td>0.008800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10050</td>\n",
              "      <td>0.007400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10100</td>\n",
              "      <td>0.013400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10150</td>\n",
              "      <td>0.010300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10200</td>\n",
              "      <td>0.007100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10250</td>\n",
              "      <td>0.003200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10300</td>\n",
              "      <td>0.008400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10350</td>\n",
              "      <td>0.017800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10400</td>\n",
              "      <td>0.016500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10450</td>\n",
              "      <td>0.008300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.013400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10550</td>\n",
              "      <td>0.011900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10600</td>\n",
              "      <td>0.017800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10650</td>\n",
              "      <td>0.011700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10700</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10750</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10800</td>\n",
              "      <td>0.006500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10850</td>\n",
              "      <td>0.005700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10900</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10950</td>\n",
              "      <td>0.009000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.004400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11050</td>\n",
              "      <td>0.016300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11100</td>\n",
              "      <td>0.006100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11150</td>\n",
              "      <td>0.006900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11200</td>\n",
              "      <td>0.005900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11250</td>\n",
              "      <td>0.001700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11300</td>\n",
              "      <td>0.005800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11350</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11400</td>\n",
              "      <td>0.005600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11450</td>\n",
              "      <td>0.007200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.013000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11550</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11600</td>\n",
              "      <td>0.015500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11650</td>\n",
              "      <td>0.003900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11700</td>\n",
              "      <td>0.010400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11750</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11800</td>\n",
              "      <td>0.006000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11850</td>\n",
              "      <td>0.009900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11900</td>\n",
              "      <td>0.012100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11950</td>\n",
              "      <td>0.005400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12050</td>\n",
              "      <td>0.007100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12100</td>\n",
              "      <td>0.006600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12150</td>\n",
              "      <td>0.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12200</td>\n",
              "      <td>0.014600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12250</td>\n",
              "      <td>0.005200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12300</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12350</td>\n",
              "      <td>0.005100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12400</td>\n",
              "      <td>0.007200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12450</td>\n",
              "      <td>0.005900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12550</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12600</td>\n",
              "      <td>0.007600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12650</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12700</td>\n",
              "      <td>0.005900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12750</td>\n",
              "      <td>0.003100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12800</td>\n",
              "      <td>0.007700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12850</td>\n",
              "      <td>0.001300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12900</td>\n",
              "      <td>0.002800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12950</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.003900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13050</td>\n",
              "      <td>0.006300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13100</td>\n",
              "      <td>0.006400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13150</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13200</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13250</td>\n",
              "      <td>0.002300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13300</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13350</td>\n",
              "      <td>0.008100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13400</td>\n",
              "      <td>0.007100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13450</td>\n",
              "      <td>0.006000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13550</td>\n",
              "      <td>0.002400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13600</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13650</td>\n",
              "      <td>0.001600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13700</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13750</td>\n",
              "      <td>0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13800</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13850</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13900</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13950</td>\n",
              "      <td>0.004900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14050</td>\n",
              "      <td>0.005700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14100</td>\n",
              "      <td>0.002700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14150</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14200</td>\n",
              "      <td>0.005500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14250</td>\n",
              "      <td>0.002300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14300</td>\n",
              "      <td>0.003000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14350</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14400</td>\n",
              "      <td>0.004700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14450</td>\n",
              "      <td>0.005900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>0.005600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14550</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14600</td>\n",
              "      <td>0.002900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14650</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14700</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14750</td>\n",
              "      <td>0.001900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14800</td>\n",
              "      <td>0.007600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14850</td>\n",
              "      <td>0.005500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14900</td>\n",
              "      <td>0.002700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14950</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.002200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15050</td>\n",
              "      <td>0.002500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15100</td>\n",
              "      <td>0.003900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15150</td>\n",
              "      <td>0.005000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15200</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15250</td>\n",
              "      <td>0.007200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15300</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15350</td>\n",
              "      <td>0.002900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15400</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15450</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15500</td>\n",
              "      <td>0.005500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15550</td>\n",
              "      <td>0.006400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15600</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15650</td>\n",
              "      <td>0.004600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15700</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15750</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15800</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15850</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15900</td>\n",
              "      <td>0.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15950</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16050</td>\n",
              "      <td>0.003100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16100</td>\n",
              "      <td>0.002500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Fine-tuned model ve tokenizer '/content/drive/MyDrive/BİTİRME/trained_bert_finetuned' klasörüne kaydedildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, multilabel_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import os\n",
        "\n",
        "metrics_dir = \"/content/drive/MyDrive/BİTİRME/metrics2\"\n",
        "os.makedirs(metrics_dir, exist_ok=True)  # Klasör yoksa oluştur\n",
        "\n",
        "# Şimdi metrikleri kaydedebilirsin\n",
        "metrics_file = os.path.join(metrics_dir, \"multi_label_metrics.txt\")\n",
        "with open(metrics_file, \"w\") as f:\n",
        "    for k,v in metrics_dict.items():\n",
        "        f.write(f\"{k}: {v:.4f}\\n\")\n",
        "\n",
        "\n",
        "# ====== Kaydedilecek klasör ======\n",
        "metrics_dir = \"/content/drive/MyDrive/BİTİRME/metrics2\"\n",
        "os.makedirs(metrics_dir, exist_ok=True)\n",
        "\n",
        "# ====== Modeli eval moduna al ======\n",
        "model.eval()\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for item in val_dataset:\n",
        "        input_ids = item['input_ids'].unsqueeze(0).to(device)\n",
        "        attention_mask = item['attention_mask'].unsqueeze(0).to(device)\n",
        "        labels = item['labels'].unsqueeze(0).to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        preds = torch.sigmoid(logits)\n",
        "        preds_binary = (preds > 0.5).float()\n",
        "\n",
        "        all_labels.append(labels.cpu().numpy())\n",
        "        all_preds.append(preds_binary.cpu().numpy())\n",
        "\n",
        "# Numpy array’e çevir\n",
        "all_labels = np.vstack(all_labels)\n",
        "all_preds = np.vstack(all_preds)\n",
        "\n",
        "# ====== Temel metrikler ======\n",
        "f1_micro = f1_score(all_labels, all_preds, average='micro')\n",
        "f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision = precision_score(all_labels, all_preds, average='micro')\n",
        "recall = recall_score(all_labels, all_preds, average='micro')\n",
        "\n",
        "metrics_dict = {\n",
        "    \"Accuracy\": accuracy,\n",
        "    \"Precision_micro\": precision,\n",
        "    \"Recall_micro\": recall,\n",
        "    \"F1_micro\": f1_micro,\n",
        "    \"F1_macro\": f1_macro\n",
        "}\n",
        "\n",
        "# Metrikleri TXT olarak kaydet\n",
        "metrics_file = os.path.join(metrics_dir, \"multi_label_metrics.txt\")\n",
        "with open(metrics_file, \"w\") as f:\n",
        "    for k,v in metrics_dict.items():\n",
        "        f.write(f\"{k}: {v:.4f}\\n\")\n",
        "\n",
        "print(f\"✅ Metrikler kaydedildi: {metrics_file}\")\n",
        "\n",
        "# ====== Confusion Matrix her etiket için ======\n",
        "mcm = multilabel_confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "for idx, cm in enumerate(mcm):\n",
        "    plt.figure(figsize=(4,3))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.title(f\"Confusion Matrix - Label {ANA_KATEGORILER[idx]}\")\n",
        "\n",
        "    # Güvenli dosya adı\n",
        "    safe_label = ANA_KATEGORILER[idx].replace(\"/\", \"_\").replace(\" \", \"_\")\n",
        "    plt.savefig(os.path.join(metrics_dir, f\"confusion_matrix_{safe_label}.png\"))\n",
        "    plt.close()\n",
        "\n",
        "print(f\"✅ Confusion matrix görselleri kaydedildi: {metrics_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEMxIZ3HPeHi",
        "outputId": "72717407-b3f1-446c-f18c-7e270c47c456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Metrikler kaydedildi: /content/drive/MyDrive/BİTİRME/metrics2/multi_label_metrics.txt\n",
            "✅ Confusion matrix görselleri kaydedildi: /content/drive/MyDrive/BİTİRME/metrics2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, multilabel_confusion_matrix, ConfusionMatrixDisplay, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "\n",
        "# ====== Klasör ======\n",
        "metrics_dir = \"/content/drive/MyDrive/BİTİRME/metrics2\"\n",
        "os.makedirs(metrics_dir, exist_ok=True)\n",
        "\n",
        "# ====== Modeli eval moduna al ======\n",
        "model.eval()\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for item in val_dataset:\n",
        "        input_ids = item['input_ids'].unsqueeze(0).to(device)\n",
        "        attention_mask = item['attention_mask'].unsqueeze(0).to(device)\n",
        "        labels = item['labels'].unsqueeze(0).to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        preds = torch.sigmoid(logits)\n",
        "        preds_binary = (preds > 0.5).float()\n",
        "\n",
        "        all_labels.append(labels.cpu().numpy())\n",
        "        all_preds.append(preds_binary.cpu().numpy())\n",
        "\n",
        "all_labels = np.vstack(all_labels)\n",
        "all_preds = np.vstack(all_preds)\n",
        "\n",
        "# ====== Temel metrikler ======\n",
        "f1_micro = f1_score(all_labels, all_preds, average='micro')\n",
        "f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision_micro = precision_score(all_labels, all_preds, average='micro')\n",
        "recall_micro = recall_score(all_labels, all_preds, average='micro')\n",
        "\n",
        "# ====== Sınıf bazlı metrikler ======\n",
        "precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "\n",
        "metrics_dict = {\n",
        "    \"Accuracy\": accuracy,\n",
        "    \"Precision_micro\": precision_micro,\n",
        "    \"Recall_micro\": recall_micro,\n",
        "    \"F1_micro\": f1_micro,\n",
        "    \"F1_macro\": f1_macro\n",
        "}\n",
        "\n",
        "# Sınıf bazlı metrikleri ekle\n",
        "for idx, label in enumerate(ANA_KATEGORILER):\n",
        "    metrics_dict[f\"Precision_{label}\"] = precision_per_class[idx]\n",
        "    metrics_dict[f\"Recall_{label}\"] = recall_per_class[idx]\n",
        "    metrics_dict[f\"F1_{label}\"] = f1_per_class[idx]\n",
        "\n",
        "# ====== TXT olarak kaydet ======\n",
        "metrics_file = os.path.join(metrics_dir, \"multi_label_metrics.txt\")\n",
        "with open(metrics_file, \"w\") as f:\n",
        "    for k,v in metrics_dict.items():\n",
        "        f.write(f\"{k}: {v:.4f}\\n\")\n",
        "print(f\"✅ Metrikler kaydedildi: {metrics_file}\")\n",
        "\n",
        "# ====== Multi-label confusion matrix her label ======\n",
        "mcm = multilabel_confusion_matrix(all_labels, all_preds)\n",
        "for idx, cm in enumerate(mcm):\n",
        "    plt.figure(figsize=(4,3))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.title(f\"Confusion Matrix - Label {ANA_KATEGORILER[idx]}\")\n",
        "    safe_label = ANA_KATEGORILER[idx].replace(\"/\", \"_\").replace(\" \", \"_\")\n",
        "    plt.savefig(os.path.join(metrics_dir, f\"confusion_matrix_{safe_label}.png\"))\n",
        "    plt.close()\n",
        "\n",
        "# ====== Tüm sınıflar için 5x5 confusion matrix ======\n",
        "# Not: Multi-label ise overlap olacağı için her label 1/0, 5x5 klasik confusion matrix mantığı biraz farklı\n",
        "# Ama burada \"en baskın etiket\" varsayımı ile tek-label gibi gösterebiliriz:\n",
        "true_labels_single = np.argmax(all_labels, axis=1)\n",
        "pred_labels_single = np.argmax(all_preds, axis=1)\n",
        "\n",
        "cm_full = confusion_matrix(true_labels_single, pred_labels_single)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm_full, annot=True, fmt='d', cmap='Blues', xticklabels=ANA_KATEGORILER, yticklabels=ANA_KATEGORILER)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix - All Classes\")\n",
        "plt.savefig(os.path.join(metrics_dir, \"confusion_matrix_all_classes.png\"))\n",
        "plt.close()\n",
        "print(f\"✅ 5x5 Confusion matrix kaydedildi: {metrics_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAC5Tvt9R011",
        "outputId": "c061febf-7ab4-4531-f45f-3b16ed6607e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Metrikler kaydedildi: /content/drive/MyDrive/BİTİRME/metrics2/multi_label_metrics.txt\n",
            "✅ 5x5 Confusion matrix kaydedildi: /content/drive/MyDrive/BİTİRME/metrics2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 1️⃣ Drive'ı Bağla\n",
        "# =========================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# =========================================================\n",
        "# 2️⃣ Model Yolunu Belirt\n",
        "# =========================================================\n",
        "model_path = \"/content/drive/MyDrive/BİTİRME/trained_bert_finetuned\"\n",
        "\n",
        "# =========================================================\n",
        "# 3️⃣ Model ve Tokenizer'ı Yükle (Local)\n",
        "# =========================================================\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path, local_files_only=True)\n",
        "model.eval()\n",
        "\n",
        "print(\"✅ Model ve tokenizer başarıyla yüklendi!\")\n",
        "\n",
        "# =========================================================\n",
        "# 4️⃣ Örnek Tahmin\n",
        "# =========================================================\n",
        "text = \"Bagajımda kırıklar oluştu ve tamir edilemez durumda yenisini verin.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predicted_class_id = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "print(\"Tahmin edilen sınıf ID:\", predicted_class_id)\n",
        "\n",
        "# Eğer etiket isimlerini biliyorsan:\n",
        "labels = [\"ÜCRET İADESİ\", \"BAGAJ\", \"MÜŞTERİ HİZMETLERİ\", \"UYGULAMA/TEKNİK\", \"RÖTAR\"]\n",
        "print(\"Tahmin edilen etiket:\", labels[predicted_class_id])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkQ9gh7mSyRI",
        "outputId": "16ca73bd-92fd-43a2-a751-68f6508eecaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Model ve tokenizer başarıyla yüklendi!\n",
            "Tahmin edilen sınıf ID: 1\n",
            "Tahmin edilen etiket: BAGAJ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "save_path = \"/content/drive/MyDrive/BİTİRME/final_model.pt\"\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(\"✅ Model kaydedildi:\", save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAWQ-IUqIBlM",
        "outputId": "f7790f9d-4491-460d-b1c2-0a5f731f9e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model kaydedildi: /content/drive/MyDrive/BİTİRME/final_model.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask transformers torch\n",
        "\n",
        "from flask import Flask, request, jsonify\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# ======= MODEL PATH =======\n",
        "MODEL_PATH = \"/content/drive/MyDrive/BİTİRME/trained_bert_finetuned\"\n",
        "\n",
        "# ======= LABELS (etiketlerin sırası) =======\n",
        "ANA_KATEGORILER = [\"ÜCRET İADESİ\", \"BAGAJ\", \"MÜŞTERİ HİZMETLERİ\", \"UYGULAMA/TEKNİK\", \"RÖTAR\"]\n",
        "\n",
        "# ======= Model & Tokenizer Yükleme =======\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)\n",
        "model = BertForSequenceClassification.from_pretrained(MODEL_PATH)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# ======= Flask App =======\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "    data = request.get_json(force=True)\n",
        "    text = data.get(\"text\", \"\")\n",
        "\n",
        "    if not text:\n",
        "        return jsonify({\"error\": \"No text provided\"}), 400\n",
        "\n",
        "    # ======= Tokenize Et =======\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=256\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        probs = torch.sigmoid(outputs.logits).cpu().numpy()[0]\n",
        "\n",
        "    # ======= Olasılıklar + Etiketler =======\n",
        "    result = {}\n",
        "    for label, p in zip(ANA_KATEGORILER, probs):\n",
        "        result[label] = float(p)\n",
        "\n",
        "    # Eşik 0.5 üzerindekileri etiket olarak ata\n",
        "    predicted_labels = [label for label, p in result.items() if p > 0.5]\n",
        "\n",
        "    return jsonify({\n",
        "        \"text\": text,\n",
        "        \"predicted_labels\": predicted_labels,\n",
        "        \"probabilities\": result\n",
        "    })\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(host=\"0.0.0.0\", port=5000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1gVDX-MIDb3",
        "outputId": "aa7e5773-2044-450b-d64b-b128bc46232f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# 1️⃣ Gerekli kütüphaneler\n",
        "# =====================================================\n",
        "!pip install transformers torch flask flask-cors\n",
        "!npm install -g localtunnel\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "import threading\n",
        "import os\n",
        "\n",
        "# =====================================================\n",
        "# 2️⃣ Model ve tokenizer yükleme\n",
        "# =====================================================\n",
        "model_path = \"/content/drive/MyDrive/BİTİRME/trained_bert_finetuned\"  # senin model yolun\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Tokenizer ve model\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# =====================================================\n",
        "# 3️⃣ Flask API\n",
        "# =====================================================\n",
        "app = Flask(__name__)\n",
        "CORS(app)  # frontend ile iletişim için\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    try:\n",
        "        data = request.json\n",
        "        text = data['text']\n",
        "\n",
        "        # Tokenize\n",
        "        inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        # Tahmin\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.sigmoid(logits)\n",
        "            preds_binary = (preds > 0.5).int().cpu().tolist()[0]\n",
        "\n",
        "        # Sınıf isimleri (senin ANA_KATEGORILER listesi)\n",
        "        ANA_KATEGORILER = [\"ÜCRET İADESİ\", \"BAGAJ\", \"MÜŞTERİ HİZMETLERİ\", \"UYGULAMA/TEKNİK\", \"RÖTAR\"]\n",
        "        prediction_dict = {label: pred for label, pred in zip(ANA_KATEGORILER, preds_binary)}\n",
        "\n",
        "        return jsonify({\"prediction\": prediction_dict})\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)})\n",
        "\n",
        "# =====================================================\n",
        "# 4️⃣ Flask arka planda çalıştır\n",
        "# =====================================================\n",
        "def run_app():\n",
        "    app.run(port=5009)\n",
        "\n",
        "threading.Thread(target=run_app).start()\n",
        "\n",
        "# =====================================================\n",
        "# 5️⃣ Localtunnel ile Colab dışına aç\n",
        "# =====================================================\n",
        "!lt --port 5009\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ewryARnJF4f",
        "outputId": "1a56d4cf-274b-4305-cf34-19aca9a2b518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.12/dist-packages (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K\n",
            "changed 22 packages in 1s\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Address already in use\n",
            "Port 5009 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your url is: https://crazy-walls-visit.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers flask flask-cors\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQeS39X6J0on",
        "outputId": "8f9976c6-289d-41a0-8367-dcc9954ecf31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.12/dist-packages (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/BİTİRME/trained_bert_finetuned\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "model = BertForSequenceClassification.from_pretrained(model_path)\n"
      ],
      "metadata": {
        "id": "IafxmIVyMk6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask-ngrok\n",
        "from flask_ngrok import run_with_ngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90N8o5VyMonp",
        "outputId": "e2b8114d-9d74-443b-ba70-dab9d17e4884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.12/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.12/dist-packages (from flask-ngrok) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from flask-ngrok) (2.32.4)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask>=0.8->flask-ngrok) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from Flask>=0.8->flask-ngrok) (8.3.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask>=0.8->flask-ngrok) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask>=0.8->flask-ngrok) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->flask-ngrok) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->flask-ngrok) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->flask-ngrok) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->flask-ngrok) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6P7n-tp9q403"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPSGkaam0af8SlLpMqsE197",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}