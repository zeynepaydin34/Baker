{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeynepaydin34/Baker/blob/main/Classification-Cleaning_Augmentation_Training_FineTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_AqeuHYd8c5",
        "outputId": "bf89c178-9e7f-4494-b90f-de1a28b41356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Temizlik tamamlandÄ±. SatÄ±r sayÄ±sÄ±: 1048\n"
          ]
        }
      ],
      "source": [
        "# 1. AdÄ±m: Drive'Ä± baÄŸla ve veri yÃ¼kle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import unicodedata\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "TEXT_COLUMN = 'temizlenmis_metin'\n",
        "ANA_KATEGORILER = ['ÃœCRET Ä°ADESÄ°','BAGAJ','MÃœÅžTERÄ° HÄ°ZMETLERÄ°','UYGULAMA/TEKNÄ°K','RÃ–TAR']\n",
        "\n",
        "# Dosya yolu\n",
        "DOSYA_ADI = '/content/drive/MyDrive/BÄ°TÄ°RME/Labeled_Data.xlsx'\n",
        "\n",
        "# Veri yÃ¼kle\n",
        "df = pd.read_excel(DOSYA_ADI)\n",
        "df.columns = [col.strip().replace(' ', '').replace('Ä°', 'I') for col in df.columns]\n",
        "\n",
        "# Metin birleÅŸtirme\n",
        "df['metin'] = df[['Baslik', 'Icerik', 'Kategori1', 'Kategori2']].fillna('').agg(' '.join, axis=1)\n",
        "\n",
        "# Temizlik iÃ§in stopwords\n",
        "stop_words_tr = set(nltk.corpus.stopwords.words('turkish'))\n",
        "ek_stop_words = {'rica', 'bilgi', 'olay', 'durum', 'yapmak', 'etmek', 'olmak',\n",
        "                 'sÃ¼re', 'deÄŸil', 'gerekli', 'taraf', 'istemek', 'istiyorum', 'yapÄ±lmasÄ±nÄ±',\n",
        "                 'gerek', 'nedeniyle', 'a', 'o', 'bu', 'ki', 'iÃ§in', 'ile', 've', 'ya', 'bir',\n",
        "                 'ben', 'sen', 'biz', 'siz'}\n",
        "stop_words_tr.update(ek_stop_words)\n",
        "\n",
        "# Temizlik fonksiyonlarÄ±\n",
        "def nlp_clean(text):\n",
        "    if pd.isna(text) or text is None: return \"\"\n",
        "    text = str(text).lower()\n",
        "    text = unicodedata.normalize('NFKC', text)\n",
        "    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
        "    text = re.sub(r'[\\dâ‚¬$â‚ºÂ£]', ' ', text)\n",
        "    text = re.sub(r'\\s*\\S+@\\S+|\\s*https?://\\S+|\\s*www\\.\\S+', ' ', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    kelimeler = text.split()\n",
        "    kelimeler = [k for k in kelimeler if k not in stop_words_tr]\n",
        "    return \" \".join(kelimeler).strip()\n",
        "\n",
        "def fix_unicode(text):\n",
        "    replacements = {'iÌ‡': 'i', 'I': 'Ä±', 'Ä°': 'i', 'Ã–': 'Ã¶', 'Ãœ': 'Ã¼', 'Ã‡': 'Ã§', 'Åž': 'ÅŸ', 'Äž': 'ÄŸ'}\n",
        "    for wrong, correct in replacements.items():\n",
        "        text = text.replace(wrong, correct)\n",
        "    return text.strip()\n",
        "\n",
        "# Temizleme uygula\n",
        "df[TEXT_COLUMN] = df['metin'].apply(nlp_clean).apply(fix_unicode)\n",
        "\n",
        "# Minimum filtreleme\n",
        "df = df[df[TEXT_COLUMN].str.split().str.len() > 3]\n",
        "df = df.dropna(subset=['Kategori1'])\n",
        "\n",
        "# Multi-label encoding\n",
        "for kategori in ANA_KATEGORILER:\n",
        "    df[kategori] = ((df['Kategori1'] == kategori) | (df['Kategori2'] == kategori)).astype(int)\n",
        "\n",
        "print(f\"âœ… Temizlik tamamlandÄ±. SatÄ±r sayÄ±sÄ±: {len(df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPm9ytzylP6l",
        "outputId": "352ce18c-ae61-4f7f-a7d3-50f608d026f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Veri Seti BoyutlarÄ±: Train: 838, Val: 105, Test: 105\n",
            "\n",
            "âœ… Veri ayÄ±rma (Train/Val/Test) tamamlandÄ±. SÄ±nÄ±f AÄŸÄ±rlÄ±ÄŸÄ± HesaplamasÄ±na geÃ§ebilirsiniz.\n"
          ]
        }
      ],
      "source": [
        "# 3. ADIM: Veriyi AyÄ±rma (Train, Validation, Test: 80-10-10)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Metinleri ve etiketleri ayÄ±r\n",
        "X = df[TEXT_COLUMN]  # df_clean yerine df kullan\n",
        "y = df[ANA_KATEGORILER]\n",
        "\n",
        "# 80% Train/Val, 10% Test\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    X, y, test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "# Kalan %90'Ä± 8/1 oranÄ±nda Train ve Val olarak ayÄ±r (yani 80% Train, 10% Val)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=(0.1/0.9), random_state=42\n",
        ")\n",
        "\n",
        "# DataFrame oluÅŸtur\n",
        "train_df = pd.DataFrame({TEXT_COLUMN: X_train, **y_train}).reset_index(drop=True)\n",
        "val_df = pd.DataFrame({TEXT_COLUMN: X_val, **y_val}).reset_index(drop=True)\n",
        "test_df = pd.DataFrame({TEXT_COLUMN: X_test, **y_test}).reset_index(drop=True)\n",
        "\n",
        "print(f\"Veri Seti BoyutlarÄ±: Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n",
        "print(\"\\nâœ… Veri ayÄ±rma (Train/Val/Test) tamamlandÄ±. SÄ±nÄ±f AÄŸÄ±rlÄ±ÄŸÄ± HesaplamasÄ±na geÃ§ebilirsiniz.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Multi-label Dengeli Oversampling (Iteratif)\n",
        "# =========================================================\n",
        "import pandas as pd\n",
        "import random\n",
        "from deep_translator import GoogleTranslator\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# GPU kontrolÃ¼\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"âœ… Ã‡alÄ±ÅŸma cihazÄ±: {device}\")\n",
        "\n",
        "# Back-Translation Fonksiyonu (CPU'da Ã§alÄ±ÅŸÄ±r)\n",
        "def back_translate(text, src='tr', mid='en'):\n",
        "    try:\n",
        "        trans = GoogleTranslator(source=src, target=mid).translate(text)\n",
        "        back = GoogleTranslator(source=mid, target=src).translate(trans)\n",
        "        if back is None or back.lower().strip() == text.lower().strip():\n",
        "            return text\n",
        "        return back\n",
        "    except Exception:\n",
        "        return text\n",
        "\n",
        "# Hedef sÄ±nÄ±f sayÄ±sÄ±nÄ± belirle (en bÃ¼yÃ¼k sÄ±nÄ±f)\n",
        "MAX_CLASS_COUNT = train_df[ANA_KATEGORILER].sum().max()\n",
        "print(\"=\"*60)\n",
        "print(\"BaÅŸlatÄ±lÄ±yor: Dengeli Oversampling + Back-Translation (Multi-label)\")\n",
        "print(f\"Orijinal TRAIN SETÄ° boyutu: {len(train_df)}\")\n",
        "print(f\"En bÃ¼yÃ¼k sÄ±nÄ±f sayÄ±sÄ± (hedef): {MAX_CLASS_COUNT}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Iteratif oversampling\n",
        "augmented_frames = []\n",
        "\n",
        "# Kopya ekleme fonksiyonu\n",
        "def add_sample(row):\n",
        "    new_row = row.copy()\n",
        "    new_row[TEXT_COLUMN] = back_translate(row[TEXT_COLUMN])\n",
        "    return new_row\n",
        "\n",
        "# TÃ¼m sÄ±nÄ±flarÄ±n hedefe ulaÅŸana kadar iteratif ekleme\n",
        "while True:\n",
        "    label_counts = train_df[ANA_KATEGORILER].sum()\n",
        "    min_class = label_counts.idxmin()\n",
        "    min_count = label_counts.min()\n",
        "\n",
        "    if min_count >= MAX_CLASS_COUNT:\n",
        "        break  # TÃ¼m sÄ±nÄ±flar hedefe ulaÅŸtÄ±\n",
        "\n",
        "    # Min sÄ±nÄ±ftan bir Ã¶rnek seÃ§\n",
        "    candidates = train_df[train_df[min_class] == 1]\n",
        "    row = candidates.sample(n=1, replace=True).iloc[0]\n",
        "    new_row = add_sample(row)\n",
        "    train_df = pd.concat([train_df, pd.DataFrame([new_row])], ignore_index=True)\n",
        "\n",
        "print(\"\\nâœ… Oversampling tamamlandÄ±.\")\n",
        "print(f\"Yeni TRAIN SETÄ° boyutu: {len(train_df)}\")\n",
        "print(\"Yeni sÄ±nÄ±f daÄŸÄ±lÄ±mlarÄ±:\")\n",
        "print(train_df[ANA_KATEGORILER].sum().sort_values(ascending=False).to_string())\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Kaydetme\n",
        "save_dir = '/content/drive/MyDrive/BÄ°TÄ°RME'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "save_path = os.path.join(save_dir, 'train_augmented_multi_label_balanced.xlsx')\n",
        "train_df.to_excel(save_path, index=False)\n",
        "print(f\"\\nâœ… ArtÄ±rÄ±lmÄ±ÅŸ ve dengeli TRAIN SETÄ° baÅŸarÄ±yla kaydedildi: {save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2UFxzBZBO0o",
        "outputId": "db23e2d6-9567-44a1-f824-132ac2387046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Ã‡alÄ±ÅŸma cihazÄ±: cuda\n",
            "============================================================\n",
            "BaÅŸlatÄ±lÄ±yor: Dengeli Oversampling + Back-Translation (Multi-label)\n",
            "Orijinal TRAIN SETÄ° boyutu: 1889\n",
            "En bÃ¼yÃ¼k sÄ±nÄ±f sayÄ±sÄ± (hedef): 966\n",
            "============================================================\n",
            "\n",
            "âœ… Oversampling tamamlandÄ±.\n",
            "Yeni TRAIN SETÄ° boyutu: 3142\n",
            "Yeni sÄ±nÄ±f daÄŸÄ±lÄ±mlarÄ±:\n",
            "ÃœCRET Ä°ADESÄ°          1487\n",
            "MÃœÅžTERÄ° HÄ°ZMETLERÄ°    1022\n",
            "BAGAJ                  967\n",
            "UYGULAMA/TEKNÄ°K        966\n",
            "RÃ–TAR                  966\n",
            "============================================================\n",
            "\n",
            "âœ… ArtÄ±rÄ±lmÄ±ÅŸ ve dengeli TRAIN SETÄ° baÅŸarÄ±yla kaydedildi: /content/drive/MyDrive/BÄ°TÄ°RME/train_augmented_multi_label_balanced.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 5. ADIM: SÄ±nÄ±flandÄ±rma Model HazÄ±rlÄ±ÄŸÄ± (DengelenmiÅŸ Veri Seti Ä°Ã§in Optimizasyon)\n",
        "\n",
        "import torch.nn as nn\n",
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import torch\n",
        "import pandas as pd\n",
        "# NOT: MODEL_NAME, ANA_KATEGORILER, TRAIN_BATCH, EVAL_BATCH, MAX_LEN, TEXT_COLUMN\n",
        "# ve train_df, val_df deÄŸiÅŸkenlerinin tanÄ±mlÄ± olduÄŸunu varsayÄ±yoruz.\n",
        "\n",
        "# CihazÄ± Belirle\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 5.1. AÄŸÄ±rlÄ±k Hesaplama (SADECE KONTROL AMAÃ‡LI TUTULDU - KULLANILMAYACAK)\n",
        "label_counts = train_df[ANA_KATEGORILER].sum()\n",
        "print(\"\\nâœ… ArtÄ±rma SonrasÄ± Yeni SÄ±nÄ±f SayÄ±mlarÄ± (Dengeli OlmalÄ±):\")\n",
        "print(label_counts.sort_values(ascending=False).to_string())\n",
        "# Not: AÅŸaÄŸÄ±daki class_weights_tensor artÄ±k CustomTrainer'da kullanÄ±lmayacaktÄ±r.\n",
        "# class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "\n",
        "# 5.2. Custom Trainer (AÄŸÄ±rlÄ±ÄŸÄ± DEVRE DIÅžI BIRAKMAK iÃ§in)\n",
        "# Veri dengelemesi yapÄ±ldÄ±ÄŸÄ± iÃ§in, aÄŸÄ±rlÄ±klÄ± Loss kaldÄ±rÄ±ldÄ±.\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # ðŸš¨ DÃœZELTME: AÄŸÄ±rlÄ±ksÄ±z Loss Hesaplama\n",
        "        # ArtÄ±k train_df dengeli olduÄŸu iÃ§in pos_weight parametresi kaldÄ±rÄ±ldÄ±.\n",
        "        loss_fct = nn.BCEWithLogitsLoss()\n",
        "        loss = loss_fct(logits, labels)\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# 5.3. Dataset HazÄ±rlÄ±ÄŸÄ± (AynÄ± kalÄ±yor)\n",
        "class ComplaintDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=MAX_LEN):\n",
        "        self.texts = texts.tolist()\n",
        "        self.labels = labels.values\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        encoding = self.tokenizer(\n",
        "            text, truncation=True, padding='max_length', max_length=self.max_len, return_tensors='pt'\n",
        "        )\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "# Tokenizer ve Dataset HazÄ±rlÄ±ÄŸÄ±\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
        "train_dataset = ComplaintDataset(train_df[TEXT_COLUMN], train_df[ANA_KATEGORILER], tokenizer, max_len=MAX_LEN)\n",
        "val_dataset = ComplaintDataset(val_df[TEXT_COLUMN], val_df[ANA_KATEGORILER], tokenizer, max_len=MAX_LEN)\n",
        "\n",
        "# Temel BERT modelini yÃ¼kle\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME, num_labels=len(ANA_KATEGORILER)\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "# Metrik Hesaplama Fonksiyonu\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    # Tahmin olasÄ±lÄ±klarÄ± hesaplanÄ±r\n",
        "    preds = torch.sigmoid(torch.tensor(pred.predictions)).numpy()\n",
        "    # VarsayÄ±lan eÅŸik 0.5 kullanÄ±lÄ±r\n",
        "    preds = (preds > 0.5).astype(int)\n",
        "    # Metrikler hesaplanÄ±r\n",
        "    f1 = f1_score(labels, preds, average='micro')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"f1\": f1, \"accuracy\": acc}\n",
        "\n",
        "# EÄŸitim Parametreleri ve Custom Trainer'Ä± OluÅŸtur\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results', num_train_epochs=12, per_device_train_batch_size=TRAIN_BATCH,\n",
        "    per_device_eval_batch_size=EVAL_BATCH,\n",
        "    # Hata Ã§Ã¶zÃ¼ldÃ¼ÄŸÃ¼ iÃ§in burayÄ± tekrar True yapabiliriz, ancak ÅŸimdilik False kalsÄ±n\n",
        "    gradient_checkpointing=False,\n",
        "    logging_steps=50,\n",
        "    learning_rate=1e-5, weight_decay=0.01, load_best_model_at_end=False,\n",
        "    logging_dir='./logs', report_to='none', fp16=True if device.type == 'cuda' else False\n",
        ")\n",
        "\n",
        "# Custom Trainer'Ä± kullan\n",
        "trainer = CustomTrainer(\n",
        "    model=model, args=training_args, train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset, compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "print(\"\\nâœ… Custom Trainer ve Model objeleri baÅŸarÄ±yla oluÅŸturuldu. EÄŸitime baÅŸlamaya hazÄ±rsÄ±nÄ±z.\")"
      ],
      "metadata": {
        "id": "NsjSV-NFPKpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================\n",
        "# 5-7. ADIM: Dengeli Multi-label EÄŸitim, Kaydetme ve Test DeÄŸerlendirme\n",
        "# ======================================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# -------------------------------\n",
        "# 0. VarsayÄ±lan deÄŸiÅŸkenler\n",
        "# -------------------------------\n",
        "MODEL_NAME = \"dbmdz/bert-base-turkish-cased\"\n",
        "ANA_KATEGORILER = ['ÃœCRET Ä°ADESÄ°','BAGAJ','MÃœÅžTERÄ° HÄ°ZMETLERÄ°','UYGULAMA/TEKNÄ°K','RÃ–TAR']\n",
        "TEXT_COLUMN = 'temizlenmis_metin'\n",
        "MAX_LEN = 128\n",
        "TRAIN_BATCH = 8\n",
        "EVAL_BATCH = 8\n",
        "\n",
        "\n",
        "# CihazÄ± Belirle\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"\\nâœ… Ã‡alÄ±ÅŸma cihazÄ±: {device}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 1. AÄŸÄ±rlÄ±k kontrolÃ¼ (sadece bilgi)\n",
        "# -------------------------------\n",
        "label_counts = train_df[ANA_KATEGORILER].sum()\n",
        "print(\"\\nâœ… ArtÄ±rma SonrasÄ± Yeni SÄ±nÄ±f SayÄ±mlarÄ± (Dengeli OlmalÄ±):\")\n",
        "print(label_counts.sort_values(ascending=False).to_string())\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Custom Trainer (AÄŸÄ±rlÄ±ksÄ±z Loss)\n",
        "# -------------------------------\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss_fct = nn.BCEWithLogitsLoss()  # pos_weight kaldÄ±rÄ±ldÄ±\n",
        "        loss = loss_fct(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Dataset SÄ±nÄ±fÄ±\n",
        "# -------------------------------\n",
        "class ComplaintDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.texts = texts.tolist()\n",
        "        self.labels = labels.values\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        encoding = self.tokenizer(\n",
        "            text, truncation=True, padding='max_length', max_length=self.max_len, return_tensors='pt'\n",
        "        )\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Tokenizer ve Dataset\n",
        "# -------------------------------\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
        "train_dataset = ComplaintDataset(train_df[TEXT_COLUMN], train_df[ANA_KATEGORILER], tokenizer, max_len=MAX_LEN)\n",
        "val_dataset = ComplaintDataset(val_df[TEXT_COLUMN], val_df[ANA_KATEGORILER], tokenizer, max_len=MAX_LEN)\n",
        "test_dataset = ComplaintDataset(test_df[TEXT_COLUMN], test_df[ANA_KATEGORILER], tokenizer, max_len=MAX_LEN)\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Model YÃ¼kleme\n",
        "# -------------------------------\n",
        "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(ANA_KATEGORILER))\n",
        "model.to(device)\n",
        "\n",
        "# -------------------------------\n",
        "# 6. Metrik Fonksiyonu\n",
        "# -------------------------------\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = torch.sigmoid(torch.tensor(pred.predictions)).numpy()\n",
        "    preds = (preds > 0.5).astype(int)\n",
        "    f1 = f1_score(labels, preds, average='micro')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"f1\": f1, \"accuracy\": acc}\n",
        "\n",
        "# -------------------------------\n",
        "# 7. EÄŸitim Parametreleri\n",
        "# -------------------------------\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/content/drive/MyDrive/BÄ°TÄ°RME/results',\n",
        "    num_train_epochs=12,\n",
        "    per_device_train_batch_size=TRAIN_BATCH,\n",
        "    per_device_eval_batch_size=EVAL_BATCH,\n",
        "    gradient_checkpointing=False,\n",
        "    logging_steps=50,\n",
        "    learning_rate=1e-5,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=False,\n",
        "    logging_dir='/content/drive/MyDrive/BÄ°TÄ°RME/logs',\n",
        "    report_to='none',\n",
        "    fp16=True if device.type=='cuda' else False\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 8. Trainer\n",
        "# -------------------------------\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 9. EÄŸitim BaÅŸlat\n",
        "# -------------------------------\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"BERT Model EÄŸitimi BAÅžLIYOR... (Batch Size: {TRAIN_BATCH})\")\n",
        "print(\"=\"*50)\n",
        "trainer.train()\n",
        "\n",
        "# -------------------------------\n",
        "# 10. Model ve Tokenizer Kaydet\n",
        "# -------------------------------\n",
        "save_path = '/content/drive/MyDrive/BÄ°TÄ°RME/trained_bert_multi_label'\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n",
        "print(f\"\\nâœ… EÄŸitim tamamlandÄ±. Model ve tokenizer '{save_path}' klasÃ¶rÃ¼ne kaydedildi.\")\n",
        "\n",
        "# -------------------------------\n",
        "# 11. Test Seti DeÄŸerlendirme\n",
        "# -------------------------------\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"TEST SETÄ° ÃœZERÄ°NDE PERFORMANS DEÄžERLENDÄ°RMESÄ°\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "results = trainer.evaluate(test_dataset)\n",
        "print(\"\\nâœ… Genel Test Metrikleri:\")\n",
        "print(results)\n",
        "\n",
        "# Tahminleri al\n",
        "predictions = trainer.predict(test_dataset)\n",
        "test_labels = predictions.label_ids\n",
        "test_preds = torch.sigmoid(torch.tensor(predictions.predictions)).numpy()\n",
        "test_preds_binary = (test_preds > 0.5).astype(int)\n",
        "\n",
        "print(\"\\nâœ… DetaylÄ± SÄ±nÄ±flandÄ±rma Raporu (SÄ±nÄ±f BazlÄ± Performans):\")\n",
        "print(classification_report(test_labels, test_preds_binary, target_names=ANA_KATEGORILER, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q0VsZLZpSaj8",
        "outputId": "e350e43f-f068-48a1-ed86-a4851b4c828b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Ã‡alÄ±ÅŸma cihazÄ±: cuda\n",
            "\n",
            "âœ… ArtÄ±rma SonrasÄ± Yeni SÄ±nÄ±f SayÄ±mlarÄ± (Dengeli OlmalÄ±):\n",
            "ÃœCRET Ä°ADESÄ°          1487\n",
            "MÃœÅžTERÄ° HÄ°ZMETLERÄ°    1022\n",
            "BAGAJ                  967\n",
            "UYGULAMA/TEKNÄ°K        966\n",
            "RÃ–TAR                  966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "BERT Model EÄŸitimi BAÅžLIYOR... (Batch Size: 8)\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4716' max='4716' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4716/4716 05:39, Epoch 12/12]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.631000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.542500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.457600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.400900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.360900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.324300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.298500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.275300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.243000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.223900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.206300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.198200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.195300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.171500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.159100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.144100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.128300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.120800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.110700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.104400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.106700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.113500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.092000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.076900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.075100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.076400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.068900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.061400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.073400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.064400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.059400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.049300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.041400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.041600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.044700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.051900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.037800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.040100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.038700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.031200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>0.034100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.024500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>0.028300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.030200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.032900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.024900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>0.026200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.022100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>0.021900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.021400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>0.021200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.019700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2650</td>\n",
              "      <td>0.018300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.017200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>0.017900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.013900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2850</td>\n",
              "      <td>0.019800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.016200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2950</td>\n",
              "      <td>0.013400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.016100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3050</td>\n",
              "      <td>0.013500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.013500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3150</td>\n",
              "      <td>0.016800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.012900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3250</td>\n",
              "      <td>0.010900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.012100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3350</td>\n",
              "      <td>0.011800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.010600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3450</td>\n",
              "      <td>0.013600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.012700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3550</td>\n",
              "      <td>0.009500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3650</td>\n",
              "      <td>0.008400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.009700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3750</td>\n",
              "      <td>0.009500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.008800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3850</td>\n",
              "      <td>0.010200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.009400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3950</td>\n",
              "      <td>0.008800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.009700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4050</td>\n",
              "      <td>0.007900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.008600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4150</td>\n",
              "      <td>0.007600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.009100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4250</td>\n",
              "      <td>0.007600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.007900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4350</td>\n",
              "      <td>0.007000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.008400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4450</td>\n",
              "      <td>0.008500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.007000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4550</td>\n",
              "      <td>0.007300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.007600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4650</td>\n",
              "      <td>0.007100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.007600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… EÄŸitim tamamlandÄ±. Model ve tokenizer '/content/drive/MyDrive/BÄ°TÄ°RME/trained_bert_multi_label' klasÃ¶rÃ¼ne kaydedildi.\n",
            "\n",
            "==================================================\n",
            "TEST SETÄ° ÃœZERÄ°NDE PERFORMANS DEÄžERLENDÄ°RMESÄ°\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Genel Test Metrikleri:\n",
            "{'eval_loss': 0.3546130955219269, 'eval_f1': 0.8389057750759878, 'eval_accuracy': 0.6285714285714286, 'eval_runtime': 0.5806, 'eval_samples_per_second': 180.856, 'eval_steps_per_second': 24.114, 'epoch': 12.0}\n",
            "\n",
            "âœ… DetaylÄ± SÄ±nÄ±flandÄ±rma Raporu (SÄ±nÄ±f BazlÄ± Performans):\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "      ÃœCRET Ä°ADESÄ°       0.84      0.86      0.85        59\n",
            "             BAGAJ       0.95      1.00      0.98        21\n",
            "MÃœÅžTERÄ° HÄ°ZMETLERÄ°       0.79      0.83      0.81        41\n",
            "   UYGULAMA/TEKNÄ°K       0.79      0.72      0.75        32\n",
            "             RÃ–TAR       0.90      0.82      0.86        11\n",
            "\n",
            "         micro avg       0.84      0.84      0.84       164\n",
            "         macro avg       0.85      0.85      0.85       164\n",
            "      weighted avg       0.84      0.84      0.84       164\n",
            "       samples avg       0.86      0.86      0.84       164\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================\n",
        "# Performans Analizi: ROC, Confusion Matrix, Inference Time\n",
        "# ======================================================================\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report, roc_auc_score, roc_curve, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "\n",
        "# -------------------------------\n",
        "# 0. Model ve Tokenizer Yolu\n",
        "# -------------------------------\n",
        "model_path = '/content/drive/MyDrive/BÄ°TÄ°RME/trained_bert_multi_label'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Dataset SÄ±nÄ±fÄ±\n",
        "# -------------------------------\n",
        "class ComplaintDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.texts = texts.tolist()\n",
        "        self.labels = labels.values\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        encoding = self.tokenizer(\n",
        "            text, truncation=True, padding='max_length', max_length=self.max_len, return_tensors='pt'\n",
        "        )\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Test Dataset ve DataLoader\n",
        "# -------------------------------\n",
        "test_dataset = ComplaintDataset(test_df[TEXT_COLUMN], test_df[ANA_KATEGORILER], tokenizer, max_len=MAX_LEN)\n",
        "test_loader = DataLoader(test_dataset, batch_size=EVAL_BATCH)\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Tahmin ve Inference Time\n",
        "# -------------------------------\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "start_time = time.time()\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs = {k: v.to(device) for k,v in batch.items() if k != 'labels'}\n",
        "        labels = batch['labels'].to(device)\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        probs = torch.sigmoid(logits)\n",
        "        all_preds.append(probs.cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "\n",
        "inference_time = time.time() - start_time\n",
        "print(f\"\\nâœ… Toplam inference sÃ¼resi: {inference_time:.4f} saniye\")\n",
        "\n",
        "all_preds = torch.cat(all_preds).numpy()\n",
        "all_labels = torch.cat(all_labels).numpy()\n",
        "all_preds_binary = (all_preds > 0.5).astype(int)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Genel ve SÄ±nÄ±f BazlÄ± Performans\n",
        "# -------------------------------\n",
        "f1_micro = f1_score(all_labels, all_preds_binary, average='micro')\n",
        "accuracy = accuracy_score(all_labels, all_preds_binary)\n",
        "print(f\"\\nâœ… Genel F1 (micro): {f1_micro:.4f}\")\n",
        "print(f\"âœ… Genel Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nâœ… DetaylÄ± SÄ±nÄ±f BazlÄ± Rapor:\")\n",
        "print(classification_report(all_labels, all_preds_binary, target_names=ANA_KATEGORILER, zero_division=0))\n",
        "\n",
        "# -------------------------------\n",
        "# 5. ROC EÄŸrileri ve AUC\n",
        "# -------------------------------\n",
        "os.makedirs('/content/drive/MyDrive/BÄ°TÄ°RME/metrics', exist_ok=True)\n",
        "plt.figure(figsize=(10,8))\n",
        "\n",
        "for i, label in enumerate(ANA_KATEGORILER):\n",
        "    fpr, tpr, _ = roc_curve(all_labels[:,i], all_preds[:,i])\n",
        "    auc = roc_auc_score(all_labels[:,i], all_preds[:,i])\n",
        "    plt.plot(fpr, tpr, label=f\"{label} (AUC={auc:.2f})\")\n",
        "\n",
        "plt.plot([0,1],[0,1],'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Multi-label ROC EÄŸrileri')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "roc_path = '/content/drive/MyDrive/BÄ°TÄ°RME/metrics/roc_curves.png'\n",
        "plt.savefig(roc_path)\n",
        "plt.close()\n",
        "print(f\"\\nâœ… ROC eÄŸrileri kaydedildi: {roc_path}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 6. Confusion Matrix (Her SÄ±nÄ±f iÃ§in)\n",
        "# -------------------------------\n",
        "cm_dir = '/content/drive/MyDrive/BÄ°TÄ°RME/metrics/confusion_matrices'\n",
        "os.makedirs(cm_dir, exist_ok=True)\n",
        "\n",
        "for i, label in enumerate(ANA_KATEGORILER):\n",
        "    cm = confusion_matrix(all_labels[:,i], all_preds_binary[:,i])\n",
        "    plt.figure(figsize=(4,4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "    plt.title(f'Confusion Matrix - {label}')\n",
        "    plt.xlabel('Tahmin')\n",
        "    plt.ylabel('GerÃ§ek')\n",
        "    safe_label = label.replace(\"/\", \"_\").replace(\" \", \"_\")  # gÃ¼venli dosya adÄ±\n",
        "    cm_path = os.path.join(cm_dir, f'confusion_{safe_label}.png')\n",
        "    plt.savefig(cm_path)\n",
        "    plt.close()\n",
        "    print(f\"âœ… {label} confusion matrix kaydedildi: {cm_path}\")\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 7. TÃ¼m metrikleri CSV olarak kaydet\n",
        "# -------------------------------\n",
        "metrics_df = pd.DataFrame({\n",
        "    'label': ANA_KATEGORILER,\n",
        "    'f1': [f1_score(all_labels[:,i], all_preds_binary[:,i]) for i in range(len(ANA_KATEGORILER))],\n",
        "    'accuracy': [accuracy_score(all_labels[:,i], all_preds_binary[:,i]) for i in range(len(ANA_KATEGORILER))],\n",
        "    'roc_auc': [roc_auc_score(all_labels[:,i], all_preds[:,i]) for i in range(len(ANA_KATEGORILER))]\n",
        "})\n",
        "metrics_path = '/content/drive/MyDrive/BÄ°TÄ°RME/metrics/per_class_metrics.csv'\n",
        "metrics_df.to_csv(metrics_path, index=False)\n",
        "print(f\"\\nâœ… SÄ±nÄ±f bazlÄ± metrikler kaydedildi: {metrics_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QawLjcWhWo3u",
        "outputId": "277527a8-ffe7-4d66-8451-1cf686a06c8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Toplam inference sÃ¼resi: 0.4775 saniye\n",
            "\n",
            "âœ… Genel F1 (micro): 0.8389\n",
            "âœ… Genel Accuracy: 0.6286\n",
            "\n",
            "âœ… DetaylÄ± SÄ±nÄ±f BazlÄ± Rapor:\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "      ÃœCRET Ä°ADESÄ°       0.84      0.86      0.85        59\n",
            "             BAGAJ       0.95      1.00      0.98        21\n",
            "MÃœÅžTERÄ° HÄ°ZMETLERÄ°       0.79      0.83      0.81        41\n",
            "   UYGULAMA/TEKNÄ°K       0.79      0.72      0.75        32\n",
            "             RÃ–TAR       0.90      0.82      0.86        11\n",
            "\n",
            "         micro avg       0.84      0.84      0.84       164\n",
            "         macro avg       0.85      0.85      0.85       164\n",
            "      weighted avg       0.84      0.84      0.84       164\n",
            "       samples avg       0.86      0.86      0.84       164\n",
            "\n",
            "\n",
            "âœ… ROC eÄŸrileri kaydedildi: /content/drive/MyDrive/BÄ°TÄ°RME/metrics/roc_curves.png\n",
            "âœ… ÃœCRET Ä°ADESÄ° confusion matrix kaydedildi: /content/drive/MyDrive/BÄ°TÄ°RME/metrics/confusion_matrices/confusion_ÃœCRET_Ä°ADESÄ°.png\n",
            "âœ… BAGAJ confusion matrix kaydedildi: /content/drive/MyDrive/BÄ°TÄ°RME/metrics/confusion_matrices/confusion_BAGAJ.png\n",
            "âœ… MÃœÅžTERÄ° HÄ°ZMETLERÄ° confusion matrix kaydedildi: /content/drive/MyDrive/BÄ°TÄ°RME/metrics/confusion_matrices/confusion_MÃœÅžTERÄ°_HÄ°ZMETLERÄ°.png\n",
            "âœ… UYGULAMA/TEKNÄ°K confusion matrix kaydedildi: /content/drive/MyDrive/BÄ°TÄ°RME/metrics/confusion_matrices/confusion_UYGULAMA_TEKNÄ°K.png\n",
            "âœ… RÃ–TAR confusion matrix kaydedildi: /content/drive/MyDrive/BÄ°TÄ°RME/metrics/confusion_matrices/confusion_RÃ–TAR.png\n",
            "\n",
            "âœ… SÄ±nÄ±f bazlÄ± metrikler kaydedildi: /content/drive/MyDrive/BÄ°TÄ°RME/metrics/per_class_metrics.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# 1. AdÄ±m: Drive'Ä± baÄŸla ve veri yÃ¼kle\n",
        "# ========================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import unicodedata\n",
        "import nltk\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "# ========================================================\n",
        "# 2. Ayarlar ve dosya yolu\n",
        "# ========================================================\n",
        "TEXT_COLUMN = 'temizlenmis_metin'\n",
        "ANA_KATEGORILER = ['ÃœCRET Ä°ADESÄ°','BAGAJ','MÃœÅžTERÄ° HÄ°ZMETLERÄ°','UYGULAMA/TEKNÄ°K','RÃ–TAR']\n",
        "\n",
        "DOSYA_ADI = '/content/drive/MyDrive/BÄ°TÄ°RME/Unlabeled_Data.xlsx'\n",
        "MODEL_DIR = '/content/drive/MyDrive/BÄ°TÄ°RME/trained_bert_multi_label'  # 1K veriden eÄŸittiÄŸin model\n",
        "SAVE_DIR = '/content/drive/MyDrive/BÄ°TÄ°RME'\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# ========================================================\n",
        "# 3. Veri yÃ¼kleme\n",
        "# ========================================================\n",
        "df = pd.read_excel(DOSYA_ADI)\n",
        "df.columns = [col.strip().replace(' ', '').replace('Ä°', 'I') for col in df.columns]\n",
        "\n",
        "# BaÅŸlÄ±k ve iÃ§erik sÃ¼tunlarÄ±nÄ± birleÅŸtir\n",
        "df['metin'] = df[['Baslik', 'Icerik']].fillna('').agg(' '.join, axis=1)\n",
        "\n",
        "# ========================================================\n",
        "# 4. Temizlik fonksiyonlarÄ±\n",
        "# ========================================================\n",
        "stop_words_tr = set(nltk.corpus.stopwords.words('turkish'))\n",
        "ek_stop_words = {'rica', 'bilgi', 'olay', 'durum', 'yapmak', 'etmek', 'olmak',\n",
        "                 'sÃ¼re', 'deÄŸil', 'gerekli', 'taraf', 'istemek', 'istiyorum', 'yapÄ±lmasÄ±nÄ±',\n",
        "                 'gerek', 'nedeniyle', 'a', 'o', 'bu', 'ki', 'iÃ§in', 'ile', 've', 'ya', 'bir',\n",
        "                 'ben', 'sen', 'biz', 'siz'}\n",
        "stop_words_tr.update(ek_stop_words)\n",
        "\n",
        "def nlp_clean(text):\n",
        "    if pd.isna(text) or text is None: return \"\"\n",
        "    text = str(text).lower()\n",
        "    text = unicodedata.normalize('NFKC', text)\n",
        "    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
        "    text = re.sub(r'[\\dâ‚¬$â‚ºÂ£]', ' ', text)\n",
        "    text = re.sub(r'\\s*\\S+@\\S+|\\s*https?://\\S+|\\s*www\\.\\S+', ' ', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    kelimeler = text.split()\n",
        "    kelimeler = [k for k in kelimeler if k not in stop_words_tr]\n",
        "    return \" \".join(kelimeler).strip()\n",
        "\n",
        "def fix_unicode(text):\n",
        "    replacements = {'iÌ‡': 'i', 'I': 'Ä±', 'Ä°': 'i', 'Ã–': 'Ã¶', 'Ãœ': 'Ã¼', 'Ã‡': 'Ã§', 'Åž': 'ÅŸ', 'Äž': 'ÄŸ'}\n",
        "    for wrong, correct in replacements.items():\n",
        "        text = text.replace(wrong, correct)\n",
        "    return text.strip()\n",
        "\n",
        "df[TEXT_COLUMN] = df['metin'].apply(nlp_clean).apply(fix_unicode)\n",
        "df = df[df[TEXT_COLUMN].str.split().str.len() > 3]\n",
        "\n",
        "print(f\"âœ… Temizlik tamamlandÄ±. SatÄ±r sayÄ±sÄ±: {len(df)}\")\n",
        "\n",
        "# ========================================================\n",
        "# 5. TemizlenmiÅŸ veriyi kaydet\n",
        "# ========================================================\n",
        "cleaned_excel = os.path.join(SAVE_DIR, \"Unlabeled_Data_cleaned.xlsx\")\n",
        "df.to_excel(cleaned_excel, index=False)\n",
        "print(f\"âœ… TemizlenmiÅŸ veri kaydedildi: {cleaned_excel}\")\n",
        "\n",
        "# ========================================================\n",
        "# 6. Otomatik etiketleme iÃ§in DataSet ve DataLoader\n",
        "# ========================================================\n",
        "class PredictDataset(Dataset):\n",
        "    def __init__(self, texts, tokenizer, max_len=128):\n",
        "        self.texts = texts.tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_len,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "\n",
        "# ========================================================\n",
        "# 7. Model ve tokenizer yÃ¼kle\n",
        "# ========================================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_DIR)\n",
        "model = BertForSequenceClassification.from_pretrained(MODEL_DIR)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# ========================================================\n",
        "# 8. Tahmin\n",
        "# ========================================================\n",
        "predict_dataset = PredictDataset(df[TEXT_COLUMN], tokenizer)\n",
        "predict_loader = DataLoader(predict_dataset, batch_size=32)\n",
        "\n",
        "all_preds = []\n",
        "with torch.no_grad():\n",
        "    for batch in predict_loader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        preds = torch.sigmoid(outputs.logits).cpu().numpy()\n",
        "        all_preds.append(preds)\n",
        "\n",
        "all_preds = np.vstack(all_preds)\n",
        "\n",
        "# ========================================================\n",
        "# 8b. SÄ±nÄ±f bazlÄ± yÃ¼ksek gÃ¼ven skoru (0.8) ile 0/1\n",
        "# ========================================================\n",
        "thresholds = {k: 0.8 for k in ANA_KATEGORILER}\n",
        "binary_preds = np.zeros_like(all_preds, dtype=int)\n",
        "for i, kategori in enumerate(ANA_KATEGORILER):\n",
        "    binary_preds[:, i] = (all_preds[:, i] >= thresholds[kategori]).astype(int)\n",
        "\n",
        "# ========================================================\n",
        "# 9. Tahminleri DataFrame'e ekle\n",
        "# ========================================================\n",
        "for i, kategori in enumerate(ANA_KATEGORILER):\n",
        "    df[kategori] = binary_preds[:, i]\n",
        "\n",
        "# ========================================================\n",
        "# 10. Kaydet\n",
        "# ========================================================\n",
        "auto_labeled_file = os.path.join(SAVE_DIR, \"Unlabeled_Data_auto_labeled.xlsx\")\n",
        "df.to_excel(auto_labeled_file, index=False)\n",
        "print(f\"âœ… Otomatik etiketlenen veri kaydedildi: {auto_labeled_file}\")\n",
        "\n",
        "print(\"âœ… Ä°ÅŸlem tamamlandÄ±.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHppYUJBjXTs",
        "outputId": "7c696d2f-0052-4d6d-fc3d-8b3016fb9b51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Temizlik tamamlandÄ±. SatÄ±r sayÄ±sÄ±: 22822\n",
            "âœ… TemizlenmiÅŸ veri kaydedildi: /content/drive/MyDrive/BÄ°TÄ°RME/Unlabeled_Data_cleaned.xlsx\n",
            "âœ… Otomatik etiketlenen veri kaydedildi: /content/drive/MyDrive/BÄ°TÄ°RME/Unlabeled_Data_auto_labeled.xlsx\n",
            "âœ… Ä°ÅŸlem tamamlandÄ±.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# 0. GEREKLÄ° KÃœTÃœPHANELER VE DRIVE BAÄžLANTISI\n",
        "# ========================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import unicodedata\n",
        "import nltk\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "# ========================================================\n",
        "# 1. AYARLAR VE DOSYA YOLLARI\n",
        "# ========================================================\n",
        "TEXT_COLUMN = 'temizlenmis_metin'\n",
        "ANA_KATEGORILER = ['ÃœCRET Ä°ADESÄ°','BAGAJ','MÃœÅžTERÄ° HÄ°ZMETLERÄ°','UYGULAMA/TEKNÄ°K','RÃ–TAR']\n",
        "\n",
        "DOSYA_ADI = '/content/drive/MyDrive/BÄ°TÄ°RME/Unlabeled_Data.xlsx'\n",
        "MODEL_DIR = '/content/drive/MyDrive/BÄ°TÄ°RME/trained_bert_multi_label'  # Ã–nceden eÄŸitilen model\n",
        "SAVE_DIR = '/content/drive/MyDrive/BÄ°TÄ°RME'\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# ========================================================\n",
        "# 2. VERÄ° YÃœKLEME VE SÃœTUN BÄ°RLEÅžTÄ°RME\n",
        "# ========================================================\n",
        "df = pd.read_excel(DOSYA_ADI)\n",
        "df.columns = [col.strip().replace(' ', '').replace('Ä°', 'I') for col in df.columns]\n",
        "df['metin'] = df[['Baslik', 'Icerik']].fillna('').agg(' '.join, axis=1)\n",
        "\n",
        "# ========================================================\n",
        "# 3. TEMÄ°ZLÄ°K FONKSÄ°YONLARI\n",
        "# ========================================================\n",
        "stop_words_tr = set(nltk.corpus.stopwords.words('turkish'))\n",
        "ek_stop_words = {'rica', 'bilgi', 'olay', 'durum', 'yapmak', 'etmek', 'olmak',\n",
        "                 'sÃ¼re', 'deÄŸil', 'gerekli', 'taraf', 'istemek', 'istiyorum', 'yapÄ±lmasÄ±nÄ±',\n",
        "                 'gerek', 'nedeniyle', 'a', 'o', 'bu', 'ki', 'iÃ§in', 'ile', 've', 'ya', 'bir',\n",
        "                 'ben', 'sen', 'biz', 'siz'}\n",
        "stop_words_tr.update(ek_stop_words)\n",
        "\n",
        "def nlp_clean(text):\n",
        "    if pd.isna(text) or text is None: return \"\"\n",
        "    text = str(text).lower()\n",
        "    text = unicodedata.normalize('NFKC', text)\n",
        "    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
        "    text = re.sub(r'[\\dâ‚¬$â‚ºÂ£]', ' ', text)\n",
        "    text = re.sub(r'\\s*\\S+@\\S+|\\s*https?://\\S+|\\s*www\\.\\S+', ' ', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    kelimeler = text.split()\n",
        "    kelimeler = [k for k in kelimeler if k not in stop_words_tr]\n",
        "    return \" \".join(kelimeler).strip()\n",
        "\n",
        "def fix_unicode(text):\n",
        "    replacements = {'iÌ‡': 'i', 'I': 'Ä±', 'Ä°': 'i', 'Ã–': 'Ã¶', 'Ãœ': 'Ã¼', 'Ã‡': 'Ã§', 'Åž': 'ÅŸ', 'Äž': 'ÄŸ'}\n",
        "    for wrong, correct in replacements.items():\n",
        "        text = text.replace(wrong, correct)\n",
        "    return text.strip()\n",
        "\n",
        "# ========================================================\n",
        "# 4. TEMÄ°ZLEME VE FÄ°LTRELEME\n",
        "# ========================================================\n",
        "df[TEXT_COLUMN] = df['metin'].apply(nlp_clean).apply(fix_unicode)\n",
        "df = df[df[TEXT_COLUMN].str.split().str.len() > 3]\n",
        "\n",
        "cleaned_excel = os.path.join(SAVE_DIR, \"Unlabeled_Data_cleaned.xlsx\")\n",
        "df.to_excel(cleaned_excel, index=False)\n",
        "print(f\"âœ… Temizlik tamamlandÄ±. SatÄ±r sayÄ±sÄ±: {len(df)}\")\n",
        "print(f\"âœ… TemizlenmiÅŸ veri kaydedildi: {cleaned_excel}\")\n",
        "\n",
        "# ========================================================\n",
        "# 5. PREDICT DATASET VE DATALOADER\n",
        "# ========================================================\n",
        "class PredictDataset(Dataset):\n",
        "    def __init__(self, texts, tokenizer, max_len=128):\n",
        "        self.texts = texts.tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_len,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "\n",
        "# ========================================================\n",
        "# 6. MODEL VE TOKENIZER YÃœKLEME\n",
        "# ========================================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_DIR)\n",
        "model = BertForSequenceClassification.from_pretrained(MODEL_DIR)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# ========================================================\n",
        "# 7. TAHMÄ°N VE 0.8 EÅžÄ°K Ä°LE OTOMATÄ°K ETÄ°KETLEME\n",
        "# ========================================================\n",
        "predict_dataset = PredictDataset(df[TEXT_COLUMN], tokenizer)\n",
        "predict_loader = DataLoader(predict_dataset, batch_size=32)\n",
        "\n",
        "all_preds = []\n",
        "with torch.no_grad():\n",
        "    for batch in predict_loader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        preds = torch.sigmoid(outputs.logits).cpu().numpy()\n",
        "        all_preds.append(preds)\n",
        "\n",
        "all_preds = np.vstack(all_preds)\n",
        "\n",
        "thresholds = {k: 0.8 for k in ANA_KATEGORILER}\n",
        "binary_preds = np.zeros_like(all_preds, dtype=int)\n",
        "for i, kategori in enumerate(ANA_KATEGORILER):\n",
        "    binary_preds[:, i] = (all_preds[:, i] >= thresholds[kategori]).astype(int)\n",
        "\n",
        "for i, kategori in enumerate(ANA_KATEGORILER):\n",
        "    df[kategori] = binary_preds[:, i]\n",
        "\n",
        "auto_labeled_file = os.path.join(SAVE_DIR, \"Unlabeled_Data_auto_labeled.xlsx\")\n",
        "df.to_excel(auto_labeled_file, index=False)\n",
        "print(f\"âœ… Otomatik etiketlenen veri kaydedildi: {auto_labeled_file}\")\n",
        "\n",
        "# ========================================================\n",
        "# 8. YÃœKSEK GÃœVEN SKORUNA SAHÄ°P VERÄ°LERÄ° AYIRMA\n",
        "# ========================================================\n",
        "df_high_conf = df[(df[ANA_KATEGORILER] == 1).any(axis=1)]\n",
        "high_conf_file = os.path.join(SAVE_DIR, \"Unlabeled_Data_high_conf.xlsx\")\n",
        "df_high_conf.to_excel(high_conf_file, index=False)\n",
        "print(f\"âœ… YÃ¼ksek gÃ¼venli veri kaydedildi: {high_conf_file}, satÄ±r sayÄ±sÄ±: {len(df_high_conf)}\")\n",
        "\n",
        "# ========================================================\n",
        "# 9. ETÄ°KETLÄ° VERÄ° Ä°LE BÄ°RLEÅžTÄ°RME\n",
        "# ========================================================\n",
        "labeled_file = os.path.join(SAVE_DIR, \"Labeled_Data.xlsx\")\n",
        "if os.path.exists(labeled_file):\n",
        "    df_labeled = pd.read_excel(labeled_file)\n",
        "    df_combined = pd.concat([df_labeled, df_high_conf], ignore_index=True)\n",
        "    combined_file = os.path.join(SAVE_DIR, \"Combined_Labeled_Data.xlsx\")\n",
        "    df_combined.to_excel(combined_file, index=False)\n",
        "    print(f\"âœ… BirleÅŸtirilmiÅŸ veri kaydedildi: {combined_file}, toplam satÄ±r sayÄ±sÄ±: {len(df_combined)}\")\n",
        "else:\n",
        "    print(\"âš ï¸ Labeled_Data.xlsx bulunamadÄ±, birleÅŸtirme atlandÄ±.\")\n",
        "\n",
        "print(\"\\nðŸŽ¯ TÃœM Ä°ÅžLEM BAÅžARIYLA TAMAMLANDI ðŸŽ¯\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfflr4FvmY64",
        "outputId": "d1b1e502-4cda-40fc-bc95-db98a53f8b95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Temizlik tamamlandÄ±. SatÄ±r sayÄ±sÄ±: 22822\n",
            "âœ… TemizlenmiÅŸ veri kaydedildi: /content/drive/MyDrive/BÄ°TÄ°RME/Unlabeled_Data_cleaned.xlsx\n",
            "âœ… Otomatik etiketlenen veri kaydedildi: /content/drive/MyDrive/BÄ°TÄ°RME/Unlabeled_Data_auto_labeled.xlsx\n",
            "âœ… YÃ¼ksek gÃ¼venli veri kaydedildi: /content/drive/MyDrive/BÄ°TÄ°RME/Unlabeled_Data_high_conf.xlsx, satÄ±r sayÄ±sÄ±: 22546\n",
            "âœ… BirleÅŸtirilmiÅŸ veri kaydedildi: /content/drive/MyDrive/BÄ°TÄ°RME/Combined_Labeled_Data.xlsx, toplam satÄ±r sayÄ±sÄ±: 23598\n",
            "\n",
            "ðŸŽ¯ TÃœM Ä°ÅžLEM BAÅžARIYLA TAMAMLANDI ðŸŽ¯\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1ï¸âƒ£ Veri yÃ¼kleme\n",
        "path = \"/content/drive/MyDrive/BÄ°TÄ°RME/Unlabeled_Data_high_conf.xlsx\"\n",
        "df = pd.read_excel(path)\n",
        "\n",
        "# 2ï¸âƒ£ SÃ¼tunlarÄ± kontrol et\n",
        "print(\"âœ… SÃ¼tunlar:\", df.columns.tolist())\n",
        "\n",
        "# 3ï¸âƒ£ En yÃ¼ksek olasÄ±lÄ±ÄŸa sahip sÃ¼tunu etiket olarak belirle\n",
        "etiket_sutunlari = ['ÃœCRET Ä°ADESÄ°', 'BAGAJ', 'MÃœÅžTERÄ° HÄ°ZMETLERÄ°', 'UYGULAMA/TEKNÄ°K', 'RÃ–TAR']\n",
        "\n",
        "# En yÃ¼ksek deÄŸeri alan sÃ¼tunu predicted_label yap\n",
        "df['predicted_label'] = df[etiket_sutunlari].idxmax(axis=1)\n",
        "\n",
        "# 4ï¸âƒ£ SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.countplot(x='predicted_label', data=df, order=df['predicted_label'].value_counts().index)\n",
        "plt.title(\"SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± (YÃ¼ksek GÃ¼venli Veri)\")\n",
        "plt.xlabel(\"Etiket\")\n",
        "plt.ylabel(\"Adet\")\n",
        "plt.show()\n",
        "\n",
        "# 5ï¸âƒ£ Kontrol\n",
        "df['predicted_label'].value_counts()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761
        },
        "id": "AXGwWESQ6_M4",
        "outputId": "fa8a8c61-0071-4bc6-8e7d-43c4c4157c46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… SÃ¼tunlar: ['Baslik', 'Icerik', 'metin', 'temizlenmis_metin', 'ÃœCRET Ä°ADESÄ°', 'BAGAJ', 'MÃœÅžTERÄ° HÄ°ZMETLERÄ°', 'UYGULAMA/TEKNÄ°K', 'RÃ–TAR']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "predicted_label\n",
              "ÃœCRET Ä°ADESÄ°          10009\n",
              "BAGAJ                  4832\n",
              "MÃœÅžTERÄ° HÄ°ZMETLERÄ°     4515\n",
              "UYGULAMA/TEKNÄ°K        2093\n",
              "RÃ–TAR                  1097\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>predicted_label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ÃœCRET Ä°ADESÄ°</th>\n",
              "      <td>10009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BAGAJ</th>\n",
              "      <td>4832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MÃœÅžTERÄ° HÄ°ZMETLERÄ°</th>\n",
              "      <td>4515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>UYGULAMA/TEKNÄ°K</th>\n",
              "      <td>2093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RÃ–TAR</th>\n",
              "      <td>1097</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyVHkJRaPLxO",
        "outputId": "432e5676-1bdc-45e0-8347-225cee2d1418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# 1ï¸âƒ£ KÃ¼tÃ¼phaneler\n",
        "# ========================================================\n",
        "!pip install deep-translator -q\n",
        "from deep_translator import GoogleTranslator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "# ========================================================\n",
        "# 2ï¸âƒ£ YÃ¼ksek gÃ¼venli veriyi oku\n",
        "# ========================================================\n",
        "df = pd.read_excel(\"/content/drive/MyDrive/BÄ°TÄ°RME/Unlabeled_Data_high_conf.xlsx\")\n",
        "\n",
        "# Hedef sÄ±nÄ±flar ve kaÃ§ Ã¶rnek istiyoruz (Ã¶rnek: her sÄ±nÄ±f 5000'e tamamlanacak)\n",
        "target_counts = {\n",
        "    'RÃ–TAR': 4000\n",
        "}\n",
        "\n",
        "TEXT_COLUMN = 'temizlenmis_metin'\n",
        "\n",
        "# ========================================================\n",
        "# 3ï¸âƒ£ Back-Translation ile veri artÄ±rma\n",
        "# ========================================================\n",
        "def back_translate(text, src='tr', tmp='en', trg='tr'):\n",
        "    try:\n",
        "        translated = GoogleTranslator(source=src, target=tmp).translate(text)\n",
        "        back_translated = GoogleTranslator(source=tmp, target=trg).translate(translated)\n",
        "        return back_translated\n",
        "    except:\n",
        "        return text  # hata olursa orijinalini dÃ¶ndÃ¼r\n",
        "\n",
        "augmented_rows = []\n",
        "\n",
        "for col, target_count in target_counts.items():\n",
        "    current_rows = df[df[col]==1]\n",
        "    n_current = len(current_rows)\n",
        "    n_to_generate = target_count - n_current\n",
        "    print(f\"{col}: mevcut={n_current}, Ã¼retilecek={n_to_generate}\")\n",
        "\n",
        "    if n_to_generate > 0:\n",
        "        for _ in tqdm(range(n_to_generate)):\n",
        "            row = current_rows.sample(1).iloc[0]\n",
        "            new_text = back_translate(row[TEXT_COLUMN])\n",
        "\n",
        "            # yeni satÄ±r oluÅŸtur\n",
        "            new_row = row.copy()\n",
        "            new_row[TEXT_COLUMN] = new_text\n",
        "            augmented_rows.append(new_row)\n",
        "\n",
        "# ========================================================\n",
        "# 4ï¸âƒ£ OluÅŸturulan satÄ±rlarÄ± DataFrameâ€™e ekle\n",
        "# ========================================================\n",
        "if augmented_rows:\n",
        "    df_augmented = pd.DataFrame(augmented_rows)\n",
        "    df_combined = pd.concat([df, df_augmented], ignore_index=True)\n",
        "else:\n",
        "    df_combined = df.copy()\n",
        "\n",
        "print(f\"âœ… Toplam satÄ±r sayÄ±sÄ±: {len(df_combined)}\")\n",
        "\n",
        "# ========================================================\n",
        "# 5ï¸âƒ£ Kaydet\n",
        "# ========================================================\n",
        "df_combined.to_excel(\"/content/drive/MyDrive/BÄ°TÄ°RME/HighConf_BackTranslated.xlsx\", index=False)\n",
        "print(\"âœ… Back-translation ile artÄ±rÄ±lmÄ±ÅŸ veri kaydedildi.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvkEKBt8k767",
        "outputId": "4bcaac61-a926-47e5-bd35-34db6941acb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RÃ–TAR: mevcut=2734, Ã¼retilecek=1266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|â–         | 21/1266 [00:16<20:54,  1.01s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81IISCd0ut7T",
        "outputId": "1a4e325a-ed9f-4d78-b043-4aa13c7a3b4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openpyxl -q\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oH4mYr7vNJ_",
        "outputId": "f141612f-092c-49e5-beaf-fdbf7bb9405c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/250.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m250.9/250.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Dosya yolu\n",
        "file_path = \"/content/drive/MyDrive/BÄ°TÄ°RME/HighConf_BackTranslated.xlsx\"\n",
        "\n",
        "# DosyayÄ± oku\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Toplam satÄ±r sayÄ±sÄ±\n",
        "print(f\"âœ… SatÄ±r sayÄ±sÄ±: {len(df)}\")\n",
        "\n",
        "# SÃ¼tunlarÄ± ve sÄ±nÄ±f sÃ¼tunlarÄ±nÄ± kontrol et\n",
        "print(f\"âœ… SÃ¼tunlar: {df.columns.tolist()}\")\n",
        "\n",
        "# SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±\n",
        "class_cols = ['RÃ–TAR', 'UYGULAMA/TEKNÄ°K', 'BAGAJ', 'ÃœCRET Ä°ADESÄ°', 'MÃœÅžTERÄ° HÄ°ZMETLERÄ°']\n",
        "for col in class_cols:\n",
        "    if col in df.columns:\n",
        "        print(f\"{col}: {df[col].sum()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIoGDp_MtO5Z",
        "outputId": "726f7d21-2df4-4edc-d16f-a57ff66aa04f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… SatÄ±r sayÄ±sÄ±: 23812\n",
            "âœ… SÃ¼tunlar: ['Baslik', 'Icerik', 'metin', 'temizlenmis_metin', 'ÃœCRET Ä°ADESÄ°', 'BAGAJ', 'MÃœÅžTERÄ° HÄ°ZMETLERÄ°', 'UYGULAMA/TEKNÄ°K', 'RÃ–TAR']\n",
            "RÃ–TAR: 4000\n",
            "UYGULAMA/TEKNÄ°K: 5188\n",
            "BAGAJ: 5902\n",
            "ÃœCRET Ä°ADESÄ°: 10698\n",
            "MÃœÅžTERÄ° HÄ°ZMETLERÄ°: 7984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# 1ï¸âƒ£ KÃ¼tÃ¼phaneler\n",
        "# ========================================================\n",
        "!pip install deep-translator -q\n",
        "from deep_translator import GoogleTranslator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "# ========================================================\n",
        "# 2ï¸âƒ£ YÃ¼ksek gÃ¼venli veriyi oku\n",
        "# ========================================================\n",
        "df = pd.read_excel(\"/content/drive/MyDrive/BÄ°TÄ°RME/HighConf_BackTranslated.xlsx\")\n",
        "\n",
        "# Hedef sÄ±nÄ±flar ve kaÃ§ Ã¶rnek istiyoruz (Ã¶rnek: her sÄ±nÄ±f 5000'e tamamlanacak)\n",
        "target_counts = {\n",
        "    'RÃ–TAR': 7500\n",
        "}\n",
        "\n",
        "TEXT_COLUMN = 'temizlenmis_metin'\n",
        "\n",
        "# ========================================================\n",
        "# 3ï¸âƒ£ Back-Translation ile veri artÄ±rma\n",
        "# ========================================================\n",
        "def back_translate(text, src='tr', tmp='en', trg='tr'):\n",
        "    try:\n",
        "        translated = GoogleTranslator(source=src, target=tmp).translate(text)\n",
        "        back_translated = GoogleTranslator(source=tmp, target=trg).translate(translated)\n",
        "        return back_translated\n",
        "    except:\n",
        "        return text  # hata olursa orijinalini dÃ¶ndÃ¼r\n",
        "\n",
        "augmented_rows = []\n",
        "\n",
        "for col, target_count in target_counts.items():\n",
        "    current_rows = df[df[col]==1]\n",
        "    n_current = len(current_rows)\n",
        "    n_to_generate = target_count - n_current\n",
        "    print(f\"{col}: mevcut={n_current}, Ã¼retilecek={n_to_generate}\")\n",
        "\n",
        "    if n_to_generate > 0:\n",
        "        for _ in tqdm(range(n_to_generate)):\n",
        "            row = current_rows.sample(1).iloc[0]\n",
        "            new_text = back_translate(row[TEXT_COLUMN])\n",
        "\n",
        "            # yeni satÄ±r oluÅŸtur\n",
        "            new_row = row.copy()\n",
        "            new_row[TEXT_COLUMN] = new_text\n",
        "            augmented_rows.append(new_row)\n",
        "\n",
        "# ========================================================\n",
        "# 4ï¸âƒ£ OluÅŸturulan satÄ±rlarÄ± DataFrameâ€™e ekle\n",
        "# ========================================================\n",
        "if augmented_rows:\n",
        "    df_augmented = pd.DataFrame(augmented_rows)\n",
        "    df_combined = pd.concat([df, df_augmented], ignore_index=True)\n",
        "else:\n",
        "    df_combined = df.copy()\n",
        "\n",
        "print(f\"âœ… Toplam satÄ±r sayÄ±sÄ±: {len(df_combined)}\")\n",
        "\n",
        "# ========================================================\n",
        "# 5ï¸âƒ£ Kaydet\n",
        "# ========================================================\n",
        "df_combined.to_excel(\"/content/drive/MyDrive/BÄ°TÄ°RME/HighConf_BackTranslated_p2.xlsx\", index=False)\n",
        "print(\"âœ… Back-translation ile artÄ±rÄ±lmÄ±ÅŸ veri kaydedildi.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axUB9QtuwMY3",
        "outputId": "1f0cbd38-88c2-4e4c-b7de-2b22e3745a89"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/42.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRÃ–TAR: mevcut=4000, Ã¼retilecek=3500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3500/3500 [36:01<00:00,  1.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Toplam satÄ±r sayÄ±sÄ±: 27312\n",
            "âœ… Back-translation ile artÄ±rÄ±lmÄ±ÅŸ veri kaydedildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# 1ï¸âƒ£ KÃ¼tÃ¼phaneler\n",
        "# ========================================================\n",
        "!pip install deep-translator -q\n",
        "from deep_translator import GoogleTranslator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "# ========================================================\n",
        "# 2ï¸âƒ£ YÃ¼ksek gÃ¼venli veriyi oku\n",
        "# ========================================================\n",
        "df = pd.read_excel(\"/content/drive/MyDrive/BÄ°TÄ°RME/HighConf_BackTranslated_p2.xlsx\")\n",
        "\n",
        "# Hedef sÄ±nÄ±flar ve kaÃ§ Ã¶rnek istiyoruz (Ã¶rnek: her sÄ±nÄ±f 5000'e tamamlanacak)\n",
        "target_counts = {\n",
        "    'BAGAJ': 7500\n",
        "}\n",
        "\n",
        "TEXT_COLUMN = 'temizlenmis_metin'\n",
        "\n",
        "# ========================================================\n",
        "# 3ï¸âƒ£ Back-Translation ile veri artÄ±rma\n",
        "# ========================================================\n",
        "def back_translate(text, src='tr', tmp='en', trg='tr'):\n",
        "    try:\n",
        "        translated = GoogleTranslator(source=src, target=tmp).translate(text)\n",
        "        back_translated = GoogleTranslator(source=tmp, target=trg).translate(translated)\n",
        "        return back_translated\n",
        "    except:\n",
        "        return text  # hata olursa orijinalini dÃ¶ndÃ¼r\n",
        "\n",
        "augmented_rows = []\n",
        "\n",
        "for col, target_count in target_counts.items():\n",
        "    current_rows = df[df[col]==1]\n",
        "    n_current = len(current_rows)\n",
        "    n_to_generate = target_count - n_current\n",
        "    print(f\"{col}: mevcut={n_current}, Ã¼retilecek={n_to_generate}\")\n",
        "\n",
        "    if n_to_generate > 0:\n",
        "        for _ in tqdm(range(n_to_generate)):\n",
        "            row = current_rows.sample(1).iloc[0]\n",
        "            new_text = back_translate(row[TEXT_COLUMN])\n",
        "\n",
        "            # yeni satÄ±r oluÅŸtur\n",
        "            new_row = row.copy()\n",
        "            new_row[TEXT_COLUMN] = new_text\n",
        "            augmented_rows.append(new_row)\n",
        "\n",
        "# ========================================================\n",
        "# 4ï¸âƒ£ OluÅŸturulan satÄ±rlarÄ± DataFrameâ€™e ekle\n",
        "# ========================================================\n",
        "if augmented_rows:\n",
        "    df_augmented = pd.DataFrame(augmented_rows)\n",
        "    df_combined = pd.concat([df, df_augmented], ignore_index=True)\n",
        "else:\n",
        "    df_combined = df.copy()\n",
        "\n",
        "print(f\"âœ… Toplam satÄ±r sayÄ±sÄ±: {len(df_combined)}\")\n",
        "\n",
        "# ========================================================\n",
        "# 5ï¸âƒ£ Kaydet\n",
        "# ========================================================\n",
        "df_combined.to_excel(\"/content/drive/MyDrive/BÄ°TÄ°RME/HighConf_BackTranslated_p3.xlsx\", index=False)\n",
        "print(\"âœ… Back-translation ile artÄ±rÄ±lmÄ±ÅŸ veri kaydedildi.\")\n"
      ],
      "metadata": {
        "id": "VkvliAxd4ov2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28a062e6-22c2-47ab-c747-6f0ab91fde65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BAGAJ: mevcut=5922, Ã¼retilecek=1578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1578/1578 [17:37<00:00,  1.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Toplam satÄ±r sayÄ±sÄ±: 28890\n",
            "âœ… Back-translation ile artÄ±rÄ±lmÄ±ÅŸ veri kaydedildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# 1ï¸âƒ£ KÃ¼tÃ¼phaneler\n",
        "# ========================================================\n",
        "!pip install deep-translator -q\n",
        "from deep_translator import GoogleTranslator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "# ========================================================\n",
        "# 2ï¸âƒ£ YÃ¼ksek gÃ¼venli veriyi oku\n",
        "# ========================================================\n",
        "df = pd.read_excel(\"/content/drive/MyDrive/BÄ°TÄ°RME/HighConf_BackTranslated_p3.xlsx\")\n",
        "\n",
        "# Hedef sÄ±nÄ±flar ve kaÃ§ Ã¶rnek istiyoruz (Ã¶rnek: her sÄ±nÄ±f 5000'e tamamlanacak)\n",
        "target_counts = {\n",
        "    'UYGULAMA/TEKNÄ°K': 7500\n",
        "}\n",
        "\n",
        "TEXT_COLUMN = 'temizlenmis_metin'\n",
        "\n",
        "# ========================================================\n",
        "# 3ï¸âƒ£ Back-Translation ile veri artÄ±rma\n",
        "# ========================================================\n",
        "def back_translate(text, src='tr', tmp='en', trg='tr'):\n",
        "    try:\n",
        "        translated = GoogleTranslator(source=src, target=tmp).translate(text)\n",
        "        back_translated = GoogleTranslator(source=tmp, target=trg).translate(translated)\n",
        "        return back_translated\n",
        "    except:\n",
        "        return text  # hata olursa orijinalini dÃ¶ndÃ¼r\n",
        "\n",
        "augmented_rows = []\n",
        "\n",
        "for col, target_count in target_counts.items():\n",
        "    current_rows = df[df[col]==1]\n",
        "    n_current = len(current_rows)\n",
        "    n_to_generate = target_count - n_current\n",
        "    print(f\"{col}: mevcut={n_current}, Ã¼retilecek={n_to_generate}\")\n",
        "\n",
        "    if n_to_generate > 0:\n",
        "        for _ in tqdm(range(n_to_generate)):\n",
        "            row = current_rows.sample(1).iloc[0]\n",
        "            new_text = back_translate(row[TEXT_COLUMN])\n",
        "\n",
        "            # yeni satÄ±r oluÅŸtur\n",
        "            new_row = row.copy()\n",
        "            new_row[TEXT_COLUMN] = new_text\n",
        "            augmented_rows.append(new_row)\n",
        "\n",
        "# ========================================================\n",
        "# 4ï¸âƒ£ OluÅŸturulan satÄ±rlarÄ± DataFrameâ€™e ekle\n",
        "# ========================================================\n",
        "if augmented_rows:\n",
        "    df_augmented = pd.DataFrame(augmented_rows)\n",
        "    df_combined = pd.concat([df, df_augmented], ignore_index=True)\n",
        "else:\n",
        "    df_combined = df.copy()\n",
        "\n",
        "print(f\"âœ… Toplam satÄ±r sayÄ±sÄ±: {len(df_combined)}\")\n",
        "\n",
        "# ========================================================\n",
        "# 5ï¸âƒ£ Kaydet\n",
        "# ========================================================\n",
        "df_combined.to_excel(\"/content/drive/MyDrive/BÄ°TÄ°RME/HighConf_BackTranslated_p4.xlsx\", index=False)\n",
        "print(\"âœ… Back-translation ile artÄ±rÄ±lmÄ±ÅŸ veri kaydedildi.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goFGx-SI9QPs",
        "outputId": "3781d911-90c0-4992-f34b-afa1e18f0a3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UYGULAMA/TEKNÄ°K: mevcut=5368, Ã¼retilecek=2132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2132/2132 [27:58<00:00,  1.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Toplam satÄ±r sayÄ±sÄ±: 31022\n",
            "âœ… Back-translation ile artÄ±rÄ±lmÄ±ÅŸ veri kaydedildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ========================================================\n",
        "# 1ï¸âƒ£ Veri yÃ¼kle\n",
        "# ========================================================\n",
        "df = pd.read_excel(\"/content/drive/MyDrive/BÄ°TÄ°RME/HighConf_BackTranslated_p4.xlsx\")\n",
        "\n",
        "etiketler = ['ÃœCRET Ä°ADESÄ°', 'BAGAJ', 'MÃœÅžTERÄ° HÄ°ZMETLERÄ°', 'UYGULAMA/TEKNÄ°K', 'RÃ–TAR']\n",
        "\n",
        "# ========================================================\n",
        "# 2ï¸âƒ£ Hedefler\n",
        "# ========================================================\n",
        "hedefler = {\n",
        "    'ÃœCRET Ä°ADESÄ°': 8000\n",
        "    # MÃœÅžTERÄ° HÄ°ZMETLERÄ°'ni artÄ±k azaltmayacaÄŸÄ±z\n",
        "}\n",
        "\n",
        "# ========================================================\n",
        "# 3ï¸âƒ£ Multi-etiketli satÄ±rlarÄ± koru\n",
        "# ========================================================\n",
        "korunacak = (df['BAGAJ'] == 1) | (df['RÃ–TAR'] == 1) | (df['UYGULAMA/TEKNÄ°K'] == 1)\n",
        "df_korunan = df[korunacak].copy()\n",
        "df_azalt = df[~korunacak].copy()\n",
        "\n",
        "print(f\"Korunan satÄ±r sayÄ±sÄ±: {len(df_korunan)}\")\n",
        "print(f\"AzaltÄ±labilir satÄ±r sayÄ±sÄ±: {len(df_azalt)}\")\n",
        "\n",
        "# ========================================================\n",
        "# 4ï¸âƒ£ Sadece ÃœCRET Ä°ADESÄ° azalt\n",
        "# ========================================================\n",
        "etiket = 'ÃœCRET Ä°ADESÄ°'\n",
        "hedef = hedefler[etiket]\n",
        "mevcut = int(df[df[etiket] == 1].shape[0])\n",
        "\n",
        "if mevcut > hedef:\n",
        "    fazla_sayi = mevcut - hedef\n",
        "    adaylar = df_azalt[df_azalt[etiket] == 1]\n",
        "    print(f\"\\n{etiket}: mevcut={mevcut}, azaltÄ±lacak={fazla_sayi}\")\n",
        "\n",
        "    if len(adaylar) > fazla_sayi:\n",
        "        silinecek = adaylar.sample(n=fazla_sayi, random_state=42)\n",
        "        df_azalt = df_azalt.drop(silinecek.index)\n",
        "    else:\n",
        "        print(\"âš ï¸ Yeterli tek etiketli aday yok, mÃ¼mkÃ¼n olan kadar azaltÄ±lacak.\")\n",
        "\n",
        "# ========================================================\n",
        "# 5ï¸âƒ£ SonuÃ§ birleÅŸtir\n",
        "# ========================================================\n",
        "son_df = pd.concat([df_korunan, df_azalt], ignore_index=True)\n",
        "\n",
        "print(\"\\nâœ… Yeni etiket daÄŸÄ±lÄ±mÄ±:\")\n",
        "print(son_df[etiketler].sum())\n",
        "print(f\"âœ… Toplam satÄ±r sayÄ±sÄ±: {len(son_df)}\")\n",
        "\n",
        "# ========================================================\n",
        "# 6ï¸âƒ£ Kaydet\n",
        "# ========================================================\n",
        "output_path = \"/content/drive/MyDrive/BÄ°TÄ°RME/HighConf_Reduced_p7.xlsx\"\n",
        "son_df.to_excel(output_path, index=False)\n",
        "print(f\"\\nâœ… Kaydedildi: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0XLS1Q-_saU",
        "outputId": "ab61c1e7-4028-4e9d-c6e0-a8f5feb98d26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Korunan satÄ±r sayÄ±sÄ±: 21683\n",
            "AzaltÄ±labilir satÄ±r sayÄ±sÄ±: 9339\n",
            "\n",
            "ÃœCRET Ä°ADESÄ°: mevcut=13465, azaltÄ±lacak=5465\n",
            "\n",
            "âœ… Yeni etiket daÄŸÄ±lÄ±mÄ±:\n",
            "ÃœCRET Ä°ADESÄ°          8000\n",
            "BAGAJ                 7811\n",
            "MÃœÅžTERÄ° HÄ°ZMETLERÄ°    6673\n",
            "UYGULAMA/TEKNÄ°K       7500\n",
            "RÃ–TAR                 7513\n",
            "dtype: int64\n",
            "âœ… Toplam satÄ±r sayÄ±sÄ±: 25557\n",
            "\n",
            "âœ… Kaydedildi: /content/drive/MyDrive/BÄ°TÄ°RME/HighConf_Reduced_p7.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxImZtxhIZ2_",
        "outputId": "996dd593-824b-41a0-aa58-8e65979eff72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# 0ï¸âƒ£ KÃ¼tÃ¼phaneler\n",
        "# =====================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# =====================================================\n",
        "# 1ï¸âƒ£ DosyalarÄ± yÃ¼kle\n",
        "# =====================================================\n",
        "train_1k = pd.read_excel(\"/content/drive/MyDrive/BÄ°TÄ°RME/train_augmented_multi_label_balanced.xlsx\")\n",
        "high_conf = pd.read_excel(\"/content/drive/MyDrive/BÄ°TÄ°RME/HighConf_Reduced_p7.xlsx\")\n",
        "\n",
        "# =====================================================\n",
        "# 2ï¸âƒ£ Gereksiz sÃ¼tunlarÄ± temizle\n",
        "# =====================================================\n",
        "for df in [train_1k, high_conf]:\n",
        "    if 'Baslik' in df.columns: df.drop(columns=['Baslik'], inplace=True)\n",
        "    if 'Icerik' in df.columns: df.drop(columns=['Icerik'], inplace=True)\n",
        "\n",
        "TEXT_COLUMN = 'temizlenmis_metin'\n",
        "ANA_KATEGORILER = ['ÃœCRET Ä°ADESÄ°','BAGAJ','MÃœÅžTERÄ° HÄ°ZMETLERÄ°','UYGULAMA/TEKNÄ°K','RÃ–TAR']\n",
        "\n",
        "# =====================================================\n",
        "# 3ï¸âƒ£ 1k modeli warm-start olarak yÃ¼kle\n",
        "# =====================================================\n",
        "MODEL_PATH_1K = '/content/drive/MyDrive/BÄ°TÄ°RME/trained_bert_multi_label'\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_PATH_1K)\n",
        "model = BertForSequenceClassification.from_pretrained(MODEL_PATH_1K, num_labels=len(ANA_KATEGORILER))\n",
        "\n",
        "# =====================================================\n",
        "# 4ï¸âƒ£ High-conf ve 1k veriyi birleÅŸtir\n",
        "# =====================================================\n",
        "combined_df = pd.concat([train_1k, high_conf], ignore_index=True)\n",
        "texts = combined_df[TEXT_COLUMN]\n",
        "labels = combined_df[ANA_KATEGORILER]\n",
        "\n",
        "# =====================================================\n",
        "# 5ï¸âƒ£ Dataset sÄ±nÄ±fÄ±\n",
        "# =====================================================\n",
        "class ComplaintDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.texts = texts.tolist()\n",
        "        self.labels = labels.values\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        encoding = self.tokenizer(\n",
        "            text, truncation=True, padding='max_length', max_length=self.max_len, return_tensors='pt'\n",
        "        )\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "dataset = ComplaintDataset(texts, labels, tokenizer)\n",
        "val_size = int(0.1*len(dataset))\n",
        "train_size = len(dataset) - val_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# =====================================================\n",
        "# 6ï¸âƒ£ Custom Trainer\n",
        "# =====================================================\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss_fct = nn.BCEWithLogitsLoss()\n",
        "        loss = loss_fct(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = torch.sigmoid(torch.tensor(pred.predictions)).numpy()\n",
        "    preds_binary = (preds > 0.5).astype(int)\n",
        "    f1 = f1_score(labels, preds_binary, average='micro')\n",
        "    acc = accuracy_score(labels, preds_binary)\n",
        "    return {\"f1\": f1, \"accuracy\": acc}\n",
        "\n",
        "# =====================================================\n",
        "# 7ï¸âƒ£ EÄŸitim parametreleri ve cihaz\n",
        "# =====================================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/content/drive/MyDrive/BÄ°TÄ°RME/results_finetune',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    learning_rate=1e-5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='/content/drive/MyDrive/BÄ°TÄ°RME/logs_finetune',\n",
        "    logging_steps=50,\n",
        "    report_to='none',\n",
        "    fp16=True if device.type=='cuda' else False\n",
        ")\n",
        "\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# =====================================================\n",
        "# 8ï¸âƒ£ Fine-tune baÅŸlat\n",
        "# =====================================================\n",
        "print(\"\\nâœ… Fine-tune baÅŸlatÄ±lÄ±yor...\")\n",
        "trainer.train()\n",
        "\n",
        "# =====================================================\n",
        "# 9ï¸âƒ£ Model ve tokenizer kaydet\n",
        "# =====================================================\n",
        "save_path = '/content/drive/MyDrive/BÄ°TÄ°RME/trained_bert_finetuned'\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n",
        "print(f\"\\nâœ… Fine-tuned model ve tokenizer '{save_path}' klasÃ¶rÃ¼ne kaydedildi.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CUGDV1g2AGAG",
        "outputId": "56cdc37f-35fb-4bd4-a685-ae59e54a12c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Fine-tune baÅŸlatÄ±lÄ±yor...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16145' max='16145' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16145/16145 18:26, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.090200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.065400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.067300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.057000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.069200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.077100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.053200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.089000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.066100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.067300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.066400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.051300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.047200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.048700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.059200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.035600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.070900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.061400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.063300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.058000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.051200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.080500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.056400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.051000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.060800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.043900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.055200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.058700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.045300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.050600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.053000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.048200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.062800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.068800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.065700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.054200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.060000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.050800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.057400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.056800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>0.048700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.041900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>0.035000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.050800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.068400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.052400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>0.046300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.039700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>0.072900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.049600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>0.036900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.053400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2650</td>\n",
              "      <td>0.034500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.070300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>0.049000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.053600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2850</td>\n",
              "      <td>0.028500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.041600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2950</td>\n",
              "      <td>0.078300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.057900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3050</td>\n",
              "      <td>0.055100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.041800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3150</td>\n",
              "      <td>0.040600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.037000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3250</td>\n",
              "      <td>0.036900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.018000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3350</td>\n",
              "      <td>0.022100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.023100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3450</td>\n",
              "      <td>0.031400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.018600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3550</td>\n",
              "      <td>0.019200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.031200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3650</td>\n",
              "      <td>0.025900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.027600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3750</td>\n",
              "      <td>0.029800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.021400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3850</td>\n",
              "      <td>0.032100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.041700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3950</td>\n",
              "      <td>0.022800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.034500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4050</td>\n",
              "      <td>0.030400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.027200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4150</td>\n",
              "      <td>0.035500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.022200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4250</td>\n",
              "      <td>0.026000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.018900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4350</td>\n",
              "      <td>0.044200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.034800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4450</td>\n",
              "      <td>0.035900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.028500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4550</td>\n",
              "      <td>0.029400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.028000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4650</td>\n",
              "      <td>0.035000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.026800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4750</td>\n",
              "      <td>0.030200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.038400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4850</td>\n",
              "      <td>0.031900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.028800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4950</td>\n",
              "      <td>0.033200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.030100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5050</td>\n",
              "      <td>0.027300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.036100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5150</td>\n",
              "      <td>0.032700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.018700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5250</td>\n",
              "      <td>0.030400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.033900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5350</td>\n",
              "      <td>0.028300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.015900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5450</td>\n",
              "      <td>0.023300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.019500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5550</td>\n",
              "      <td>0.026000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.034600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5650</td>\n",
              "      <td>0.018500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.026600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5750</td>\n",
              "      <td>0.021000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.026400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5850</td>\n",
              "      <td>0.023000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.018900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5950</td>\n",
              "      <td>0.018300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.032000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6050</td>\n",
              "      <td>0.022200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.023400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6150</td>\n",
              "      <td>0.020400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.010800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6250</td>\n",
              "      <td>0.021000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.023300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6350</td>\n",
              "      <td>0.026900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.033100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6450</td>\n",
              "      <td>0.027100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.006600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6550</td>\n",
              "      <td>0.027000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.014900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6650</td>\n",
              "      <td>0.015100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.026400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6750</td>\n",
              "      <td>0.014000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.009000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6850</td>\n",
              "      <td>0.017000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.012700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6950</td>\n",
              "      <td>0.010700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.017800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7050</td>\n",
              "      <td>0.023500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.012700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7150</td>\n",
              "      <td>0.014100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.012500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7250</td>\n",
              "      <td>0.009300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.007100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7350</td>\n",
              "      <td>0.011400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.016100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7450</td>\n",
              "      <td>0.017700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.005800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7550</td>\n",
              "      <td>0.025600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.008500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7650</td>\n",
              "      <td>0.014800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.013400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7750</td>\n",
              "      <td>0.016500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.022200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7850</td>\n",
              "      <td>0.015300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.012400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7950</td>\n",
              "      <td>0.017400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.013100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8050</td>\n",
              "      <td>0.020400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.015500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8150</td>\n",
              "      <td>0.017900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.020300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8250</td>\n",
              "      <td>0.011100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.018300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8350</td>\n",
              "      <td>0.017300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.016500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8450</td>\n",
              "      <td>0.013600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.008100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8550</td>\n",
              "      <td>0.013200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.023600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8650</td>\n",
              "      <td>0.017800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>0.021300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8750</td>\n",
              "      <td>0.009300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.016600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8850</td>\n",
              "      <td>0.021500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8900</td>\n",
              "      <td>0.009300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8950</td>\n",
              "      <td>0.019100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.017200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9050</td>\n",
              "      <td>0.010700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9100</td>\n",
              "      <td>0.016700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9150</td>\n",
              "      <td>0.016200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.016200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9250</td>\n",
              "      <td>0.015100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9300</td>\n",
              "      <td>0.012200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9350</td>\n",
              "      <td>0.007100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.015800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9450</td>\n",
              "      <td>0.007900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.014200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9550</td>\n",
              "      <td>0.015000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9600</td>\n",
              "      <td>0.022800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9650</td>\n",
              "      <td>0.004900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9700</td>\n",
              "      <td>0.006800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9750</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9800</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9850</td>\n",
              "      <td>0.010900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9900</td>\n",
              "      <td>0.002400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9950</td>\n",
              "      <td>0.008800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10050</td>\n",
              "      <td>0.007400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10100</td>\n",
              "      <td>0.013400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10150</td>\n",
              "      <td>0.010300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10200</td>\n",
              "      <td>0.007100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10250</td>\n",
              "      <td>0.003200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10300</td>\n",
              "      <td>0.008400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10350</td>\n",
              "      <td>0.017800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10400</td>\n",
              "      <td>0.016500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10450</td>\n",
              "      <td>0.008300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.013400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10550</td>\n",
              "      <td>0.011900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10600</td>\n",
              "      <td>0.017800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10650</td>\n",
              "      <td>0.011700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10700</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10750</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10800</td>\n",
              "      <td>0.006500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10850</td>\n",
              "      <td>0.005700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10900</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10950</td>\n",
              "      <td>0.009000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.004400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11050</td>\n",
              "      <td>0.016300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11100</td>\n",
              "      <td>0.006100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11150</td>\n",
              "      <td>0.006900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11200</td>\n",
              "      <td>0.005900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11250</td>\n",
              "      <td>0.001700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11300</td>\n",
              "      <td>0.005800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11350</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11400</td>\n",
              "      <td>0.005600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11450</td>\n",
              "      <td>0.007200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.013000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11550</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11600</td>\n",
              "      <td>0.015500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11650</td>\n",
              "      <td>0.003900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11700</td>\n",
              "      <td>0.010400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11750</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11800</td>\n",
              "      <td>0.006000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11850</td>\n",
              "      <td>0.009900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11900</td>\n",
              "      <td>0.012100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11950</td>\n",
              "      <td>0.005400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12050</td>\n",
              "      <td>0.007100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12100</td>\n",
              "      <td>0.006600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12150</td>\n",
              "      <td>0.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12200</td>\n",
              "      <td>0.014600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12250</td>\n",
              "      <td>0.005200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12300</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12350</td>\n",
              "      <td>0.005100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12400</td>\n",
              "      <td>0.007200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12450</td>\n",
              "      <td>0.005900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12550</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12600</td>\n",
              "      <td>0.007600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12650</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12700</td>\n",
              "      <td>0.005900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12750</td>\n",
              "      <td>0.003100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12800</td>\n",
              "      <td>0.007700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12850</td>\n",
              "      <td>0.001300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12900</td>\n",
              "      <td>0.002800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12950</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.003900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13050</td>\n",
              "      <td>0.006300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13100</td>\n",
              "      <td>0.006400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13150</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13200</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13250</td>\n",
              "      <td>0.002300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13300</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13350</td>\n",
              "      <td>0.008100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13400</td>\n",
              "      <td>0.007100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13450</td>\n",
              "      <td>0.006000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13550</td>\n",
              "      <td>0.002400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13600</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13650</td>\n",
              "      <td>0.001600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13700</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13750</td>\n",
              "      <td>0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13800</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13850</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13900</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13950</td>\n",
              "      <td>0.004900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14050</td>\n",
              "      <td>0.005700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14100</td>\n",
              "      <td>0.002700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14150</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14200</td>\n",
              "      <td>0.005500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14250</td>\n",
              "      <td>0.002300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14300</td>\n",
              "      <td>0.003000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14350</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14400</td>\n",
              "      <td>0.004700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14450</td>\n",
              "      <td>0.005900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>0.005600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14550</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14600</td>\n",
              "      <td>0.002900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14650</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14700</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14750</td>\n",
              "      <td>0.001900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14800</td>\n",
              "      <td>0.007600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14850</td>\n",
              "      <td>0.005500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14900</td>\n",
              "      <td>0.002700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14950</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.002200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15050</td>\n",
              "      <td>0.002500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15100</td>\n",
              "      <td>0.003900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15150</td>\n",
              "      <td>0.005000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15200</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15250</td>\n",
              "      <td>0.007200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15300</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15350</td>\n",
              "      <td>0.002900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15400</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15450</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15500</td>\n",
              "      <td>0.005500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15550</td>\n",
              "      <td>0.006400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15600</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15650</td>\n",
              "      <td>0.004600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15700</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15750</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15800</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15850</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15900</td>\n",
              "      <td>0.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15950</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16050</td>\n",
              "      <td>0.003100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16100</td>\n",
              "      <td>0.002500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Fine-tuned model ve tokenizer '/content/drive/MyDrive/BÄ°TÄ°RME/trained_bert_finetuned' klasÃ¶rÃ¼ne kaydedildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, multilabel_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import os\n",
        "\n",
        "metrics_dir = \"/content/drive/MyDrive/BÄ°TÄ°RME/metrics2\"\n",
        "os.makedirs(metrics_dir, exist_ok=True)  # KlasÃ¶r yoksa oluÅŸtur\n",
        "\n",
        "# Åžimdi metrikleri kaydedebilirsin\n",
        "metrics_file = os.path.join(metrics_dir, \"multi_label_metrics.txt\")\n",
        "with open(metrics_file, \"w\") as f:\n",
        "    for k,v in metrics_dict.items():\n",
        "        f.write(f\"{k}: {v:.4f}\\n\")\n",
        "\n",
        "\n",
        "# ====== Kaydedilecek klasÃ¶r ======\n",
        "metrics_dir = \"/content/drive/MyDrive/BÄ°TÄ°RME/metrics2\"\n",
        "os.makedirs(metrics_dir, exist_ok=True)\n",
        "\n",
        "# ====== Modeli eval moduna al ======\n",
        "model.eval()\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for item in val_dataset:\n",
        "        input_ids = item['input_ids'].unsqueeze(0).to(device)\n",
        "        attention_mask = item['attention_mask'].unsqueeze(0).to(device)\n",
        "        labels = item['labels'].unsqueeze(0).to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        preds = torch.sigmoid(logits)\n",
        "        preds_binary = (preds > 0.5).float()\n",
        "\n",
        "        all_labels.append(labels.cpu().numpy())\n",
        "        all_preds.append(preds_binary.cpu().numpy())\n",
        "\n",
        "# Numpy arrayâ€™e Ã§evir\n",
        "all_labels = np.vstack(all_labels)\n",
        "all_preds = np.vstack(all_preds)\n",
        "\n",
        "# ====== Temel metrikler ======\n",
        "f1_micro = f1_score(all_labels, all_preds, average='micro')\n",
        "f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision = precision_score(all_labels, all_preds, average='micro')\n",
        "recall = recall_score(all_labels, all_preds, average='micro')\n",
        "\n",
        "metrics_dict = {\n",
        "    \"Accuracy\": accuracy,\n",
        "    \"Precision_micro\": precision,\n",
        "    \"Recall_micro\": recall,\n",
        "    \"F1_micro\": f1_micro,\n",
        "    \"F1_macro\": f1_macro\n",
        "}\n",
        "\n",
        "# Metrikleri TXT olarak kaydet\n",
        "metrics_file = os.path.join(metrics_dir, \"multi_label_metrics.txt\")\n",
        "with open(metrics_file, \"w\") as f:\n",
        "    for k,v in metrics_dict.items():\n",
        "        f.write(f\"{k}: {v:.4f}\\n\")\n",
        "\n",
        "print(f\"âœ… Metrikler kaydedildi: {metrics_file}\")\n",
        "\n",
        "# ====== Confusion Matrix her etiket iÃ§in ======\n",
        "mcm = multilabel_confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "for idx, cm in enumerate(mcm):\n",
        "    plt.figure(figsize=(4,3))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.title(f\"Confusion Matrix - Label {ANA_KATEGORILER[idx]}\")\n",
        "\n",
        "    # GÃ¼venli dosya adÄ±\n",
        "    safe_label = ANA_KATEGORILER[idx].replace(\"/\", \"_\").replace(\" \", \"_\")\n",
        "    plt.savefig(os.path.join(metrics_dir, f\"confusion_matrix_{safe_label}.png\"))\n",
        "    plt.close()\n",
        "\n",
        "print(f\"âœ… Confusion matrix gÃ¶rselleri kaydedildi: {metrics_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEMxIZ3HPeHi",
        "outputId": "72717407-b3f1-446c-f18c-7e270c47c456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Metrikler kaydedildi: /content/drive/MyDrive/BÄ°TÄ°RME/metrics2/multi_label_metrics.txt\n",
            "âœ… Confusion matrix gÃ¶rselleri kaydedildi: /content/drive/MyDrive/BÄ°TÄ°RME/metrics2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, multilabel_confusion_matrix, ConfusionMatrixDisplay, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "\n",
        "# ====== KlasÃ¶r ======\n",
        "metrics_dir = \"/content/drive/MyDrive/BÄ°TÄ°RME/metrics2\"\n",
        "os.makedirs(metrics_dir, exist_ok=True)\n",
        "\n",
        "# ====== Modeli eval moduna al ======\n",
        "model.eval()\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for item in val_dataset:\n",
        "        input_ids = item['input_ids'].unsqueeze(0).to(device)\n",
        "        attention_mask = item['attention_mask'].unsqueeze(0).to(device)\n",
        "        labels = item['labels'].unsqueeze(0).to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        preds = torch.sigmoid(logits)\n",
        "        preds_binary = (preds > 0.5).float()\n",
        "\n",
        "        all_labels.append(labels.cpu().numpy())\n",
        "        all_preds.append(preds_binary.cpu().numpy())\n",
        "\n",
        "all_labels = np.vstack(all_labels)\n",
        "all_preds = np.vstack(all_preds)\n",
        "\n",
        "# ====== Temel metrikler ======\n",
        "f1_micro = f1_score(all_labels, all_preds, average='micro')\n",
        "f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision_micro = precision_score(all_labels, all_preds, average='micro')\n",
        "recall_micro = recall_score(all_labels, all_preds, average='micro')\n",
        "\n",
        "# ====== SÄ±nÄ±f bazlÄ± metrikler ======\n",
        "precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "\n",
        "metrics_dict = {\n",
        "    \"Accuracy\": accuracy,\n",
        "    \"Precision_micro\": precision_micro,\n",
        "    \"Recall_micro\": recall_micro,\n",
        "    \"F1_micro\": f1_micro,\n",
        "    \"F1_macro\": f1_macro\n",
        "}\n",
        "\n",
        "# SÄ±nÄ±f bazlÄ± metrikleri ekle\n",
        "for idx, label in enumerate(ANA_KATEGORILER):\n",
        "    metrics_dict[f\"Precision_{label}\"] = precision_per_class[idx]\n",
        "    metrics_dict[f\"Recall_{label}\"] = recall_per_class[idx]\n",
        "    metrics_dict[f\"F1_{label}\"] = f1_per_class[idx]\n",
        "\n",
        "# ====== TXT olarak kaydet ======\n",
        "metrics_file = os.path.join(metrics_dir, \"multi_label_metrics.txt\")\n",
        "with open(metrics_file, \"w\") as f:\n",
        "    for k,v in metrics_dict.items():\n",
        "        f.write(f\"{k}: {v:.4f}\\n\")\n",
        "print(f\"âœ… Metrikler kaydedildi: {metrics_file}\")\n",
        "\n",
        "# ====== Multi-label confusion matrix her label ======\n",
        "mcm = multilabel_confusion_matrix(all_labels, all_preds)\n",
        "for idx, cm in enumerate(mcm):\n",
        "    plt.figure(figsize=(4,3))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.title(f\"Confusion Matrix - Label {ANA_KATEGORILER[idx]}\")\n",
        "    safe_label = ANA_KATEGORILER[idx].replace(\"/\", \"_\").replace(\" \", \"_\")\n",
        "    plt.savefig(os.path.join(metrics_dir, f\"confusion_matrix_{safe_label}.png\"))\n",
        "    plt.close()\n",
        "\n",
        "# ====== TÃ¼m sÄ±nÄ±flar iÃ§in 5x5 confusion matrix ======\n",
        "# Not: Multi-label ise overlap olacaÄŸÄ± iÃ§in her label 1/0, 5x5 klasik confusion matrix mantÄ±ÄŸÄ± biraz farklÄ±\n",
        "# Ama burada \"en baskÄ±n etiket\" varsayÄ±mÄ± ile tek-label gibi gÃ¶sterebiliriz:\n",
        "true_labels_single = np.argmax(all_labels, axis=1)\n",
        "pred_labels_single = np.argmax(all_preds, axis=1)\n",
        "\n",
        "cm_full = confusion_matrix(true_labels_single, pred_labels_single)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm_full, annot=True, fmt='d', cmap='Blues', xticklabels=ANA_KATEGORILER, yticklabels=ANA_KATEGORILER)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix - All Classes\")\n",
        "plt.savefig(os.path.join(metrics_dir, \"confusion_matrix_all_classes.png\"))\n",
        "plt.close()\n",
        "print(f\"âœ… 5x5 Confusion matrix kaydedildi: {metrics_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAC5Tvt9R011",
        "outputId": "c061febf-7ab4-4531-f45f-3b16ed6607e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Metrikler kaydedildi: /content/drive/MyDrive/BÄ°TÄ°RME/metrics2/multi_label_metrics.txt\n",
            "âœ… 5x5 Confusion matrix kaydedildi: /content/drive/MyDrive/BÄ°TÄ°RME/metrics2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 1ï¸âƒ£ Drive'Ä± BaÄŸla\n",
        "# =========================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# =========================================================\n",
        "# 2ï¸âƒ£ Model Yolunu Belirt\n",
        "# =========================================================\n",
        "model_path = \"/content/drive/MyDrive/BÄ°TÄ°RME/trained_bert_finetuned\"\n",
        "\n",
        "# =========================================================\n",
        "# 3ï¸âƒ£ Model ve Tokenizer'Ä± YÃ¼kle (Local)\n",
        "# =========================================================\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path, local_files_only=True)\n",
        "model.eval()\n",
        "\n",
        "print(\"âœ… Model ve tokenizer baÅŸarÄ±yla yÃ¼klendi!\")\n",
        "\n",
        "# =========================================================\n",
        "# 4ï¸âƒ£ Ã–rnek Tahmin\n",
        "# =========================================================\n",
        "text = \"BagajÄ±mda kÄ±rÄ±klar oluÅŸtu ve tamir edilemez durumda yenisini verin.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predicted_class_id = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "print(\"Tahmin edilen sÄ±nÄ±f ID:\", predicted_class_id)\n",
        "\n",
        "# EÄŸer etiket isimlerini biliyorsan:\n",
        "labels = [\"ÃœCRET Ä°ADESÄ°\", \"BAGAJ\", \"MÃœÅžTERÄ° HÄ°ZMETLERÄ°\", \"UYGULAMA/TEKNÄ°K\", \"RÃ–TAR\"]\n",
        "print(\"Tahmin edilen etiket:\", labels[predicted_class_id])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkQ9gh7mSyRI",
        "outputId": "16ca73bd-92fd-43a2-a751-68f6508eecaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Model ve tokenizer baÅŸarÄ±yla yÃ¼klendi!\n",
            "Tahmin edilen sÄ±nÄ±f ID: 1\n",
            "Tahmin edilen etiket: BAGAJ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "save_path = \"/content/drive/MyDrive/BÄ°TÄ°RME/final_model.pt\"\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(\"âœ… Model kaydedildi:\", save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAWQ-IUqIBlM",
        "outputId": "f7790f9d-4491-460d-b1c2-0a5f731f9e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model kaydedildi: /content/drive/MyDrive/BÄ°TÄ°RME/final_model.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask transformers torch\n",
        "\n",
        "from flask import Flask, request, jsonify\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# ======= MODEL PATH =======\n",
        "MODEL_PATH = \"/content/drive/MyDrive/BÄ°TÄ°RME/trained_bert_finetuned\"\n",
        "\n",
        "# ======= LABELS (etiketlerin sÄ±rasÄ±) =======\n",
        "ANA_KATEGORILER = [\"ÃœCRET Ä°ADESÄ°\", \"BAGAJ\", \"MÃœÅžTERÄ° HÄ°ZMETLERÄ°\", \"UYGULAMA/TEKNÄ°K\", \"RÃ–TAR\"]\n",
        "\n",
        "# ======= Model & Tokenizer YÃ¼kleme =======\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)\n",
        "model = BertForSequenceClassification.from_pretrained(MODEL_PATH)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# ======= Flask App =======\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "    data = request.get_json(force=True)\n",
        "    text = data.get(\"text\", \"\")\n",
        "\n",
        "    if not text:\n",
        "        return jsonify({\"error\": \"No text provided\"}), 400\n",
        "\n",
        "    # ======= Tokenize Et =======\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=256\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        probs = torch.sigmoid(outputs.logits).cpu().numpy()[0]\n",
        "\n",
        "    # ======= OlasÄ±lÄ±klar + Etiketler =======\n",
        "    result = {}\n",
        "    for label, p in zip(ANA_KATEGORILER, probs):\n",
        "        result[label] = float(p)\n",
        "\n",
        "    # EÅŸik 0.5 Ã¼zerindekileri etiket olarak ata\n",
        "    predicted_labels = [label for label, p in result.items() if p > 0.5]\n",
        "\n",
        "    return jsonify({\n",
        "        \"text\": text,\n",
        "        \"predicted_labels\": predicted_labels,\n",
        "        \"probabilities\": result\n",
        "    })\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(host=\"0.0.0.0\", port=5000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1gVDX-MIDb3",
        "outputId": "aa7e5773-2044-450b-d64b-b128bc46232f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# 1ï¸âƒ£ Gerekli kÃ¼tÃ¼phaneler\n",
        "# =====================================================\n",
        "!pip install transformers torch flask flask-cors\n",
        "!npm install -g localtunnel\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "import threading\n",
        "import os\n",
        "\n",
        "# =====================================================\n",
        "# 2ï¸âƒ£ Model ve tokenizer yÃ¼kleme\n",
        "# =====================================================\n",
        "model_path = \"/content/drive/MyDrive/BÄ°TÄ°RME/trained_bert_finetuned\"  # senin model yolun\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Tokenizer ve model\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# =====================================================\n",
        "# 3ï¸âƒ£ Flask API\n",
        "# =====================================================\n",
        "app = Flask(__name__)\n",
        "CORS(app)  # frontend ile iletiÅŸim iÃ§in\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    try:\n",
        "        data = request.json\n",
        "        text = data['text']\n",
        "\n",
        "        # Tokenize\n",
        "        inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        # Tahmin\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.sigmoid(logits)\n",
        "            preds_binary = (preds > 0.5).int().cpu().tolist()[0]\n",
        "\n",
        "        # SÄ±nÄ±f isimleri (senin ANA_KATEGORILER listesi)\n",
        "        ANA_KATEGORILER = [\"ÃœCRET Ä°ADESÄ°\", \"BAGAJ\", \"MÃœÅžTERÄ° HÄ°ZMETLERÄ°\", \"UYGULAMA/TEKNÄ°K\", \"RÃ–TAR\"]\n",
        "        prediction_dict = {label: pred for label, pred in zip(ANA_KATEGORILER, preds_binary)}\n",
        "\n",
        "        return jsonify({\"prediction\": prediction_dict})\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)})\n",
        "\n",
        "# =====================================================\n",
        "# 4ï¸âƒ£ Flask arka planda Ã§alÄ±ÅŸtÄ±r\n",
        "# =====================================================\n",
        "def run_app():\n",
        "    app.run(port=5009)\n",
        "\n",
        "threading.Thread(target=run_app).start()\n",
        "\n",
        "# =====================================================\n",
        "# 5ï¸âƒ£ Localtunnel ile Colab dÄ±ÅŸÄ±na aÃ§\n",
        "# =====================================================\n",
        "!lt --port 5009\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ewryARnJF4f",
        "outputId": "1a56d4cf-274b-4305-cf34-19aca9a2b518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.12/dist-packages (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0K\n",
            "changed 22 packages in 1s\n",
            "\u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0K * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Address already in use\n",
            "Port 5009 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your url is: https://crazy-walls-visit.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers flask flask-cors\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQeS39X6J0on",
        "outputId": "8f9976c6-289d-41a0-8367-dcc9954ecf31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.12/dist-packages (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/BÄ°TÄ°RME/trained_bert_finetuned\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "model = BertForSequenceClassification.from_pretrained(model_path)\n"
      ],
      "metadata": {
        "id": "IafxmIVyMk6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask-ngrok\n",
        "from flask_ngrok import run_with_ngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90N8o5VyMonp",
        "outputId": "e2b8114d-9d74-443b-ba70-dab9d17e4884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.12/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.12/dist-packages (from flask-ngrok) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from flask-ngrok) (2.32.4)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask>=0.8->flask-ngrok) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from Flask>=0.8->flask-ngrok) (8.3.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask>=0.8->flask-ngrok) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask>=0.8->flask-ngrok) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->flask-ngrok) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->flask-ngrok) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->flask-ngrok) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->flask-ngrok) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6P7n-tp9q403"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPSGkaam0af8SlLpMqsE197",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}